# Complete Git Changes - All Staged and Unstaged Diffs

Generated on: Fri 15 Aug 2025 16:21:20 PDT
Branch: chore/remove-unnecesary-secure-db

## Complete Staged Changes

```diff

```

## Unstaged Changes

```diff
diff --git a/.gitignore b/.gitignore
index b102857..2bfe49d 100644
--- a/.gitignore
+++ b/.gitignore
@@ -65,9 +65,4 @@ coverage/
 
 # cursor / cline
 .cursor-tasks.md
-memory-bank/
-
-*.md
-!README.md
-!CLAUDE.md
-!TESTING.md
\ No newline at end of file
+memory-bank/
\ No newline at end of file
diff --git a/dev.js b/dev.js
index 1512aaa..ab29c25 100755
--- a/dev.js
+++ b/dev.js
@@ -81,41 +81,33 @@ function startElectron() {
     `ðŸ”Œ Starting Electron app with Vite server at port ${vitePort}...`,
   );
 
-  // 1) Build schemas first
+  // Build schemas and TypeScript main layer
   try {
     console.log('ðŸ“‹ Building IPC schemas...');
     execSync('npm run build:schemas', { stdio: 'inherit' });
     
-    // 2) Compile TS main layer so build/main exists
     console.log('ðŸ› ï¸  Compiling main-layer TypeScript...');
-    const buildProc = spawn("node", ["scripts/build-main-ts.js"], { stdio: "inherit", shell: platform() === "win32" });
-    buildProc.on('close', (code) => {
-      if (code !== 0) {
-        console.error(`âŒ build-main-ts failed with code ${code}`);
-        viteProcess.kill();
-        process.exit(code ?? 1);
-      } else {
-        // 3) Start Electron with SecureIpcLayer enabled
-        const electronProcess = spawn("npm", ["start"], {
-          stdio: "inherit",
-          shell: platform() === "win32", // Use shell on Windows
-          env: {
-            ...process.env,
-            NODE_ENV: "development",
-            ELECTRON_START_URL: `http://localhost:${vitePort}`,
-            SECURE_IPC: "1",
-          },
-        });
-
-        electronProcess.on("close", (code) => {
-          console.log(`Electron process exited with code ${code}`);
-          viteProcess.kill();
-          process.exit(code);
-        });
-      }
+    execSync('npm run build:main', { stdio: 'inherit' });
+    
+    // Start Electron
+    const electronProcess = spawn("npm", ["start"], {
+      stdio: "inherit",
+      shell: platform() === "win32", // Use shell on Windows
+      env: {
+        ...process.env,
+        NODE_ENV: "development",
+        ELECTRON_START_URL: `http://localhost:${vitePort}`,
+        // SECURE_IPC removed - no longer using secure database path
+      },
+    });
+
+    electronProcess.on("close", (code) => {
+      console.log(`Electron process exited with code ${code}`);
+      viteProcess.kill();
+      process.exit(code);
     });
   } catch (err) {
-    console.error('âŒ Failed to compile main-layer TypeScript:', err?.message || err);
+    console.error('âŒ Failed to build schemas:', err?.message || err);
     viteProcess.kill();
     process.exit(1);
   }
diff --git a/main.js b/main.js
index fa6efa4..e01cacd 100644
--- a/main.js
+++ b/main.js
@@ -12,26 +12,7 @@ const { DatabaseBridge } = require("./src/main/db/database-bridge.js");
 // Zod schemas (CommonJS) for main process validation
 const zSchemas = require("./lib/main/ipc/schemas.cjs");
 
-// Feature flag to enable SecureIpcLayer path (TS compiled to build/main)
-const useSecureIpc = process.env.SECURE_IPC === '1';
-
-let SecureIpcLayer, StateHandlers, SecureDatabase;
-let secureIpcAvailable = false;
-
-try {
-  if (useSecureIpc) {
-    ({ SecureIpcLayer } = require("./build/main/ipc/secure-ipc.js"));
-    ({ StateHandlers } = require("./build/main/handlers/state-handlers.js"));
-    ({ SecureDatabase } = require("./build/main/db/secure-database.js"));
-    secureIpcAvailable = true;
-  }
-} catch (e) {
-  console.warn("Secure IPC modules not available; falling back to legacy handlers:", e?.message || e);
-  secureIpcAvailable = false;
-}
-
-// Use secure IPC only if requested AND available
-const actuallyUseSecureIpc = useSecureIpc && secureIpcAvailable;
+// SecureIpc has been removed - always use legacy handlers
 
 
 // Add error handling for console operations to prevent EIO errors
@@ -376,27 +357,20 @@ function createWindow() {
 // eslint-disable-next-line unicorn/prefer-top-level-await
 app.whenReady().then(async () => {
   try {
-    if (actuallyUseSecureIpc && SecureDatabase) {
-      // Initialize SecureDatabase (TS compiled to JS)
-      const userDataPath = app.getPath('userData');
-      const dbPath = path.join(userDataPath, 'pasteflow-secure.db');
-      database = await SecureDatabase.create(dbPath);
-      database.initialized = true; // flag to keep logic compatible below
-      console.log('SecureDatabase initialized successfully');
-
-      // Wire SecureIpcLayer + StateHandlers
-      if (SecureIpcLayer && StateHandlers) {
-        const ipcLayer = new SecureIpcLayer();
-        // StateHandlers will register handlers on constructor
-        // Use the same database instance
-        new StateHandlers(database, ipcLayer);
-      }
-    } else {
-      // Initialize legacy DatabaseBridge
-      database = new DatabaseBridge();
-      await database.initialize();
-      console.log('Database initialized successfully');
+    // Check for legacy secure database file
+    const userDataPath = app.getPath('userData');
+    const secureDbPath = path.join(userDataPath, 'pasteflow-secure.db');
+    
+    if (fs.existsSync(secureDbPath)) {
+      console.log('Notice: Found legacy secure database file at:', secureDbPath);
+      console.log('This file is no longer used and can be safely deleted.');
+      // Optionally, we could show a dialog to the user or auto-delete with permission
     }
+    
+    // Initialize DatabaseBridge (legacy is now the only path)
+    database = new DatabaseBridge();
+    await database.initialize();
+    console.log('Database initialized successfully');
   } catch (error) {
     console.error('Failed to initialize database:', error);
     console.log('Falling back to in-memory storage');
@@ -1014,7 +988,6 @@ ipcMain.handle('request-file-content', async (event, filePath) => {
 });
 
 // Workspace management handlers
-if (!actuallyUseSecureIpc) {
 
 ipcMain.handle('/workspace/list', async () => {
   try {
@@ -1083,16 +1056,17 @@ ipcMain.handle('/workspace/load', async (event, params) => {
     // Use database if available
     if (database && database.initialized) {
       const workspace = await database.getWorkspace(id);
-      if (!workspace) {
-        throw new Error('Workspace not found');
-      }
-      return workspace;
+      // Return null for non-existent workspaces instead of throwing
+      // This is expected during workspace auto-generation
+      return workspace || null;
     }
 
     // Fallback to in-memory store
     const workspace = workspaceStore.get(id);
     if (!workspace) {
-      throw new Error('Workspace not found');
+      // Return null for non-existent workspaces instead of throwing
+      // This is expected during workspace auto-generation
+      return null;
     }
 
     return {
@@ -1240,12 +1214,8 @@ ipcMain.handle('/workspace/rename', async (event, params) => {
   } catch (error) {
     console.error('Error renaming workspace:', error);
     return { success: false, error: error.message };
-}
-
+  }
 });
-}
-
-if (!actuallyUseSecureIpc) {
 
 // Instructions handlers
 ipcMain.handle('/instructions/list', async () => {
@@ -1298,7 +1268,6 @@ ipcMain.handle('/instructions/delete', async (event, params) => {
     throw error;
   }
 });
-}
 
 // Helper function to broadcast updates to all renderer processes
 function broadcastUpdate(channel, data) {
@@ -1308,8 +1277,6 @@ function broadcastUpdate(channel, data) {
   }
 }
 
-if (!actuallyUseSecureIpc) {
-
 // Preferences handlers
 ipcMain.handle('/prefs/get', async (event, params) => {
   try {
@@ -1383,5 +1350,3 @@ ipcMain.handle('/prefs/set', async (event, params) => {
   }
 });
 
-}
-
diff --git a/package-lock.json b/package-lock.json
index 045ecd0..343a209 100644
--- a/package-lock.json
+++ b/package-lock.json
@@ -20,10 +20,8 @@
         "gpt-3-encoder": "^1.1.4",
         "ignore": "^7.0.3",
         "jotai": "^2.12.3",
-        "keytar": "^7.9.0",
         "limiter": "^3.0.0",
         "lucide-react": "^0.477.0",
-        "node-machine-id": "^1.1.12",
         "react": "^18.2.0",
         "react-dom": "^18.2.0",
         "react-modal": "^3.16.3",
@@ -12026,23 +12024,6 @@
         "node": ">=4.0"
       }
     },
-    "node_modules/keytar": {
-      "version": "7.9.0",
-      "resolved": "https://registry.npmjs.org/keytar/-/keytar-7.9.0.tgz",
-      "integrity": "sha512-VPD8mtVtm5JNtA2AErl6Chp06JBfy7diFQ7TQQhdpWOl6MrCRB+eRbvAZUsbGQS9kiMq0coJsy0W0vHpDCkWsQ==",
-      "hasInstallScript": true,
-      "license": "MIT",
-      "dependencies": {
-        "node-addon-api": "^4.3.0",
-        "prebuild-install": "^7.0.1"
-      }
-    },
-    "node_modules/keytar/node_modules/node-addon-api": {
-      "version": "4.3.0",
-      "resolved": "https://registry.npmjs.org/node-addon-api/-/node-addon-api-4.3.0.tgz",
-      "integrity": "sha512-73sE9+3UaLYYFmDsFZnqCInzPyh3MqIwZO9cw58yIqAZhONrrabrYyYe3TuIqtIiOuTXVhsGau8hcrhhwSsDIQ==",
-      "license": "MIT"
-    },
     "node_modules/keyv": {
       "version": "4.5.4",
       "resolved": "https://registry.npmjs.org/keyv/-/keyv-4.5.4.tgz",
@@ -12707,12 +12688,6 @@
       "dev": true,
       "license": "MIT"
     },
-    "node_modules/node-machine-id": {
-      "version": "1.1.12",
-      "resolved": "https://registry.npmjs.org/node-machine-id/-/node-machine-id-1.1.12.tgz",
-      "integrity": "sha512-QNABxbrPa3qEIfrE6GOJ7BYIuignnJw7iQ2YPbc3Nla1HzRJjXzZOiikfF8m7eAMfichLt3M4VgLOetqgDmgGQ==",
-      "license": "MIT"
-    },
     "node_modules/node-releases": {
       "version": "2.0.19",
       "resolved": "https://registry.npmjs.org/node-releases/-/node-releases-2.0.19.tgz",
diff --git a/package.json b/package.json
index 836d7ed..4445c27 100644
--- a/package.json
+++ b/package.json
@@ -4,7 +4,6 @@
   "main": "main.js",
   "scripts": {
     "start": "electron .",
-    "start:secure": "SECURE_IPC=1 electron .",
     "build:main": "node scripts/build-main-ts.js",
     "build:schemas": "node scripts/build-schemas.js",
     "dev": "vite",
@@ -160,10 +159,8 @@
     "gpt-3-encoder": "^1.1.4",
     "ignore": "^7.0.3",
     "jotai": "^2.12.3",
-    "keytar": "^7.9.0",
     "limiter": "^3.0.0",
     "lucide-react": "^0.477.0",
-    "node-machine-id": "^1.1.12",
     "react": "^18.2.0",
     "react-dom": "^18.2.0",
     "react-modal": "^3.16.3",
diff --git a/scripts/build-main-ts.js b/scripts/build-main-ts.js
index ba04341..13efa4b 100644
--- a/scripts/build-main-ts.js
+++ b/scripts/build-main-ts.js
@@ -38,15 +38,12 @@ async function copyDir(srcDir, destDir) {
     // Copy runtime assets required by compiled main layer
     const assets = [
       ['src/main/db/database-worker.js', 'build/main/db/database-worker.js'],
-      ['src/main/db/schema.sql', 'build/main/db/schema.sql'],
     ];
     for (const [src, dest] of assets) {
       if (fs.existsSync(src)) {
         await copyFile(src, dest);
       }
     }
-    // Copy migrations directory
-    await copyDir('src/main/db/migrations', 'build/main/db/migrations');
 
     console.log('Main TS compiled to CommonJS at build/main');
     process.exit(0);
diff --git a/src/hooks/use-database-workspace-state.ts b/src/hooks/use-database-workspace-state.ts
index 8e234b5..8a2dd60 100644
--- a/src/hooks/use-database-workspace-state.ts
+++ b/src/hooks/use-database-workspace-state.ts
@@ -149,11 +149,10 @@ export const useDatabaseWorkspaceState = () => {
       if (!window.electron) return null;
       
       // Try to load the workspace - it may not exist yet which is fine
-      // The backend now returns null instead of throwing for non-existent workspaces
       const workspace = await window.electron.ipcRenderer.invoke('/workspace/load', { id: name });
       return workspace || null;
     } catch (error) {
-      // Only log unexpected errors
+      // Log unexpected errors
       const errorMessage = error instanceof Error ? error.message : String(error);
       console.error(`Failed to find workspace '${name}': ${errorMessage}`);
       return null;
@@ -281,8 +280,9 @@ export const useDatabaseWorkspaceState = () => {
         
         return state ?? null;
       } catch (error) {
-        console.error(`Failed to load workspace '${name}': ${(error as Error).message}`);
-        safeSetError(`Failed to load workspace '${name}': ${(error as Error).message}. Verify workspace exists and database is accessible.`);
+        const errorMessage = (error as Error).message;
+        console.error(`Failed to load workspace '${name}': ${errorMessage}`);
+        safeSetError(`Failed to load workspace '${name}': ${errorMessage}. Verify workspace exists and database is accessible.`);
         return null;
       } finally {
         safeSetIsLoading(false);
diff --git a/src/main/db/__tests__/async-database-test.ts b/src/main/db/__tests__/async-database-test.ts
deleted file mode 100644
index 746fd05..0000000
--- a/src/main/db/__tests__/async-database-test.ts
+++ /dev/null
@@ -1,430 +0,0 @@
-import * as fs from 'node:fs/promises';
-import * as path from 'node:path';
-import * as os from 'node:os';
-import { fileURLToPath } from 'node:url';
-
-import { AsyncDatabase } from '../async-database';
-
-const __dirname = path.dirname(fileURLToPath(import.meta.url));
-
-// Test SQL constants
-const INSERT_WORKSPACE_SQL = `
-  INSERT INTO workspaces (name, folder_path, state, last_accessed)
-  VALUES (?, ?, ?, ?)
-`;
-
-describe('AsyncDatabase', () => {
-  let db: AsyncDatabase;
-  let testDbPath: string;
-  let tempDir: string;
-
-  beforeEach(async () => {
-    // Create a temporary directory for test database
-    tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'pasteflow-test-'));
-    testDbPath = path.join(tempDir, 'test.db');
-    
-    // Initialize database with schema
-    db = new AsyncDatabase(testDbPath);
-    const schemaSQL = await fs.readFile(
-      path.join(__dirname, '..', 'schema.sql'),
-      'utf8'
-    );
-    await db.exec(schemaSQL);
-  });
-
-  afterEach(async () => {
-    // Clean up
-    if (db) {
-      await db.close();
-    }
-    await fs.rm(tempDir, { recursive: true, force: true });
-  });
-
-  describe('Basic CRUD operations', () => {
-    it('should insert and retrieve workspace data correctly', async () => {
-      // Create test data
-      const workspaceData = {
-        id: 'test-workspace-123',
-        name: 'My Test Workspace',
-        folderPath: '/test/path/to/workspace',
-        state: { selectedFiles: [], expandedNodes: {} }
-      };
-
-      // Insert workspace
-      const result = await db.run(
-        INSERT_WORKSPACE_SQL,
-        [workspaceData.id, workspaceData.name, workspaceData.folderPath, JSON.stringify(workspaceData.state)]
-      );
-
-      // Verify insertion
-      expect(result.changes).toBe(1);
-      expect(result.lastInsertRowid).toBeDefined();
-
-      // Retrieve workspace
-      const workspace = await db.get<{
-        id: string;
-        name: string;
-        folder_path: string;
-        state_json: string;
-      }>('SELECT * FROM workspaces WHERE id = ?', [workspaceData.id]);
-
-      // Verify retrieved data
-      expect(workspace).toBeDefined();
-      expect(workspace?.name).toBe(workspaceData.name);
-      expect(workspace?.folder_path).toBe(workspaceData.folderPath);
-      expect(JSON.parse(workspace?.state_json || '{}')).toEqual(workspaceData.state);
-    });
-
-    it('should update existing records and maintain timestamps', async () => {
-      // Insert initial workspace
-      const id = 'update-test-123';
-      await db.run(
-        INSERT_WORKSPACE_SQL,
-        [id, 'Initial Name', '/initial/path', '{}']
-      );
-
-      // Get initial timestamps
-      const initial = await db.get<{ created_at: number; updated_at: number }>(
-        'SELECT created_at, updated_at FROM workspaces WHERE id = ?',
-        [id]
-      );
-
-      // Wait a bit to ensure timestamp difference
-      await new Promise(resolve => setTimeout(resolve, 10));
-
-      // Update workspace
-      const newState = { selectedFiles: ['file1.ts', 'file2.ts'] };
-      await db.run(
-        'UPDATE workspaces SET name = ?, state_json = ? WHERE id = ?',
-        ['Updated Name', JSON.stringify(newState), id]
-      );
-
-      // Verify update
-      const updated = await db.get<{
-        name: string;
-        state_json: string;
-        created_at: number;
-        updated_at: number;
-      }>('SELECT * FROM workspaces WHERE id = ?', [id]);
-
-      expect(updated?.name).toBe('Updated Name');
-      expect(JSON.parse(updated?.state_json || '{}')).toEqual(newState);
-      expect(updated?.created_at).toBe(initial?.created_at);
-      expect(updated?.updated_at).toBeGreaterThan(initial?.updated_at || 0);
-    });
-
-    it('should delete records with cascade to related tables', async () => {
-      const workspaceId = 'delete-test-123';
-      
-      // Insert workspace and related files
-      await db.run(
-        INSERT_WORKSPACE_SQL,
-        [workspaceId, 'Delete Test', '/delete/test', '{}']
-      );
-
-      await db.run(
-        'INSERT INTO files (path, workspace_id, size, is_binary) VALUES (?, ?, ?, ?)',
-        ['/test/file1.ts', workspaceId, 1000, 0]
-      );
-
-      await db.run(
-        'INSERT INTO files (path, workspace_id, size, is_binary) VALUES (?, ?, ?, ?)',
-        ['/test/file2.ts', workspaceId, 2000, 0]
-      );
-
-      // Verify files exist
-      const filesBefore = await db.all(
-        'SELECT * FROM files WHERE workspace_id = ?',
-        [workspaceId]
-      );
-      expect(filesBefore).toHaveLength(2);
-
-      // Delete workspace
-      const deleteResult = await db.run(
-        'DELETE FROM workspaces WHERE id = ?',
-        [workspaceId]
-      );
-      expect(deleteResult.changes).toBe(1);
-
-      // Verify cascade deletion
-      const filesAfter = await db.all(
-        'SELECT * FROM files WHERE workspace_id = ?',
-        [workspaceId]
-      );
-      expect(filesAfter).toHaveLength(0);
-
-      const workspace = await db.get(
-        'SELECT * FROM workspaces WHERE id = ?',
-        [workspaceId]
-      );
-      expect(workspace).toBeUndefined();
-    });
-  });
-
-  describe('Transaction handling', () => {
-    it('should commit successful transactions', async () => {
-      const result = await db.transaction(async () => {
-        // Insert multiple related records
-        await db.run(
-          INSERT_WORKSPACE_SQL,
-          ['trans-1', 'Transaction Test 1', '/trans/1', '{}']
-        );
-
-        await db.run(
-          INSERT_WORKSPACE_SQL,
-          ['trans-2', 'Transaction Test 2', '/trans/2', '{}']
-        );
-
-        return 'success';
-      });
-
-      expect(result).toBe('success');
-
-      // Verify both records exist
-      const count = await db.get<{ count: number }>(
-        'SELECT COUNT(*) as count FROM workspaces WHERE id LIKE ?',
-        ['trans-%']
-      );
-      expect(count?.count).toBe(2);
-    });
-
-    it('should rollback failed transactions', async () => {
-      let error: Error | null = null;
-
-      try {
-        await db.transaction(async () => {
-          // First insert should succeed
-          await db.run(
-            INSERT_WORKSPACE_SQL,
-            ['rollback-1', 'Rollback Test', '/rollback', '{}']
-          );
-
-          // Second insert should fail due to unique constraint
-          await db.run(
-            INSERT_WORKSPACE_SQL,
-            ['rollback-1', 'Duplicate ID', '/rollback2', '{}']
-          );
-        });
-      } catch (error_) {
-        error = error_ as Error;
-      }
-
-      // Verify error occurred
-      expect(error).not.toBeNull();
-      expect(error?.message).toContain('UNIQUE constraint failed');
-
-      // Verify rollback - no records should exist
-      const count = await db.get<{ count: number }>(
-        'SELECT COUNT(*) as count FROM workspaces WHERE id LIKE ?',
-        ['rollback-%']
-      );
-      expect(count?.count).toBe(0);
-    });
-
-    it('should handle nested transactions correctly', async () => {
-      const result = await db.transaction(async () => {
-        await db.run(
-          INSERT_WORKSPACE_SQL,
-          ['nested-1', 'Nested Test 1', '/nested/1', '{}']
-        );
-
-        // Nested transaction (should use savepoints)
-        const innerResult = await db.transaction(async () => {
-          await db.run(
-            INSERT_WORKSPACE_SQL,
-            ['nested-2', 'Nested Test 2', '/nested/2', '{}']
-          );
-          return 'inner-success';
-        });
-
-        expect(innerResult).toBe('inner-success');
-        return 'outer-success';
-      });
-
-      expect(result).toBe('outer-success');
-
-      // Verify both records exist
-      const workspaces = await db.all<{ id: string }>(
-        'SELECT id FROM workspaces WHERE id LIKE ? ORDER BY id',
-        ['nested-%']
-      );
-      expect(workspaces).toHaveLength(2);
-      expect(workspaces.map(w => w.id)).toEqual(['nested-1', 'nested-2']);
-    });
-  });
-
-  describe('Prepared statements', () => {
-    it('should reuse prepared statements for better performance', async () => {
-      const stmt = await db.prepare(
-        'INSERT INTO files (path, workspace_id, size, is_binary) VALUES (?, ?, ?, ?)'
-      );
-
-      // Insert multiple files using the same prepared statement
-      const files = Array.from({ length: 100 }, (_, i) => ({
-        path: `/test/file${i}.ts`,
-        workspaceId: 'perf-test',
-        size: Math.floor(Math.random() * 10_000),
-        isBinary: false
-      }));
-
-      // First create the workspace
-      await db.run(
-        INSERT_WORKSPACE_SQL,
-        ['perf-test', 'Performance Test', '/perf', '{}']
-      );
-
-      // Insert files
-      for (const file of files) {
-        const result = await stmt.run(
-          file.path,
-          file.workspaceId,
-          file.size,
-          file.isBinary ? 1 : 0
-        );
-        expect(result.changes).toBe(1);
-      }
-
-      // Finalize statement
-      await stmt.finalize();
-
-      // Verify all files were inserted
-      const count = await db.get<{ count: number }>(
-        'SELECT COUNT(*) as count FROM files WHERE workspace_id = ?',
-        ['perf-test']
-      );
-      expect(count?.count).toBe(100);
-    });
-
-    it('should handle prepared statement errors gracefully', async () => {
-      const stmt = await db.prepare('SELECT * FROM workspaces WHERE id = ?');
-
-      // Use with valid parameter
-      const result1 = await stmt.get<{ id: string }>('valid-id');
-      expect(result1).toBeUndefined(); // No record exists
-
-      // Use with multiple parameters (should handle gracefully)
-      const result2 = await stmt.all<{ id: string }>('another-id');
-      expect(result2).toEqual([]);
-
-      await stmt.finalize();
-    });
-  });
-
-  describe('Concurrent operations', () => {
-    it('should handle multiple concurrent reads', async () => {
-      // Insert test data
-      const workspaces = Array.from({ length: 10 }, (_, i) => ({
-        id: `concurrent-${i}`,
-        name: `Concurrent Test ${i}`,
-        folderPath: `/concurrent/${i}`,
-        state: {}
-      }));
-
-      for (const ws of workspaces) {
-        await db.run(
-          INSERT_WORKSPACE_SQL,
-          [ws.id, ws.name, ws.folderPath, JSON.stringify(ws.state)]
-        );
-      }
-
-      // Perform concurrent reads
-      const readPromises = workspaces.map(ws =>
-        db.get<{ name: string }>('SELECT name FROM workspaces WHERE id = ?', [ws.id])
-      );
-
-      const results = await Promise.all(readPromises);
-
-      // Verify all reads succeeded
-      expect(results).toHaveLength(10);
-      for (const [i, result] of results.entries()) {
-        expect(result?.name).toBe(`Concurrent Test ${i}`);
-      }
-    });
-
-    it('should serialize writes to prevent conflicts', async () => {
-      // Create workspace for concurrent updates
-      await db.run(
-        INSERT_WORKSPACE_SQL,
-        ['write-test', 'Write Test', '/write', '{"counter": 0}']
-      );
-
-      // Perform concurrent updates
-      const updatePromises = Array.from({ length: 50 }, (_, i) =>
-        db.run(
-          'UPDATE workspaces SET state_json = ? WHERE id = ?',
-          [JSON.stringify({ counter: i + 1 }), 'write-test']
-        )
-      );
-
-      const results = await Promise.all(updatePromises);
-
-      // Verify all updates succeeded
-      expect(results).toHaveLength(50);
-      for (const result of results) {
-        expect(result.changes).toBe(1);
-      }
-
-      // Check final state
-      const final = await db.get<{ state_json: string }>(
-        'SELECT state_json FROM workspaces WHERE id = ?',
-        ['write-test']
-      );
-      const finalState = JSON.parse(final?.state_json || '{}');
-      expect(finalState.counter).toBe(50);
-    });
-  });
-
-  describe('Error handling', () => {
-    it('should provide meaningful error messages for constraint violations', async () => {
-      // Insert workspace
-      await db.run(
-        INSERT_WORKSPACE_SQL,
-        ['error-test', 'Error Test', '/error', '{}']
-      );
-
-      // Try to insert duplicate
-      await expect(
-        db.run(
-          INSERT_WORKSPACE_SQL,
-          ['error-test', 'Duplicate', '/error2', '{}']
-        )
-      ).rejects.toThrow('UNIQUE constraint failed');
-    });
-
-    it('should handle invalid SQL gracefully', async () => {
-      await expect(
-        db.run('INSERT INTO non_existent_table (id) VALUES (?)', ['test'])
-      ).rejects.toThrow('no such table: non_existent_table');
-
-      await expect(
-        db.get('SELECT * FROM workspaces WHERE invalid_column = ?', ['test'])
-      ).rejects.toThrow('no such column: invalid_column');
-    });
-
-    it('should timeout long-running queries', async () => {
-      // This is a conceptual test - in real implementation, you'd need to
-      // configure the timeout and create a query that takes longer
-      const longRunningQuery = `
-        WITH RECURSIVE long_query(n) AS (
-          SELECT 1
-          UNION ALL
-          SELECT n + 1 FROM long_query WHERE n < 1000000
-        )
-        SELECT COUNT(*) FROM long_query
-      `;
-
-      // Note: This test might need adjustment based on actual timeout implementation
-      // For now, we're testing that the query execution doesn't hang indefinitely
-      const startTime = Date.now();
-      try {
-        await db.get(longRunningQuery);
-      } catch {
-        // Expected to timeout or error
-      }
-      const duration = Date.now() - startTime;
-      
-      // Should not take more than 35 seconds (30s timeout + overhead)
-      expect(duration).toBeLessThan(35_000);
-    });
-  });
-});
\ No newline at end of file
diff --git a/src/main/db/__tests__/benchmarks.ts b/src/main/db/__tests__/benchmarks.ts
deleted file mode 100644
index 165f93a..0000000
--- a/src/main/db/__tests__/benchmarks.ts
+++ /dev/null
@@ -1,508 +0,0 @@
-import { performance } from 'node:perf_hooks';
-import * as fs from 'node:fs/promises';
-import * as path from 'node:path';
-import * as os from 'node:os';
-import { createHash } from 'node:crypto';
-import { fileURLToPath } from 'node:url';
-
-import { AsyncDatabase } from '../async-database';
-
-const __dirname = path.dirname(fileURLToPath(import.meta.url));
-
-interface BenchmarkResult {
-  operation: string;
-  duration: number;
-  opsPerSecond: number;
-  details?: Record<string, unknown>;
-}
-
-export class DatabaseBenchmarks {
-  private results: BenchmarkResult[] = [];
-  private db!: AsyncDatabase;
-  private dbPath!: string;
-  private tempDir!: string;
-
-  async setup() {
-    // Create temporary directory and database
-    this.tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'pasteflow-bench-'));
-    this.dbPath = path.join(this.tempDir, 'benchmark.db');
-    this.db = new AsyncDatabase(this.dbPath);
-    
-    // Initialize schema
-    const schemaSQL = await fs.readFile(
-      path.join(__dirname, '..', 'schema.sql'),
-      'utf8'
-    );
-    await this.db.exec(schemaSQL);
-  }
-
-  async teardown() {
-    await this.db.close();
-    await fs.rm(this.tempDir, { recursive: true, force: true });
-  }
-
-  async runAllBenchmarks() {
-    await this.setup();
-    
-    console.log('Running PasteFlow Database Benchmarks...
');
-    
-    await this.benchmarkInserts();
-    await this.benchmarkReads();
-    await this.benchmarkTransactions();
-    await this.benchmarkConcurrentReads();
-    await this.benchmarkFileOperations();
-    await this.benchmarkWorkspaceOperations();
-    
-    const report = this.generateReport();
-    
-    await this.teardown();
-    
-    return report;
-  }
-
-  private async benchmarkInserts() {
-    console.log('Benchmarking INSERT operations...');
-    
-    // Prepare test data
-    const testFiles = Array.from({ length: 10_000 }, (_, i) => ({
-      path: `/test/file${i}.ts`,
-      workspaceId: 'bench-workspace',
-      size: Math.floor(Math.random() * 100_000),
-      isBinary: false,
-      tokenCount: Math.floor(Math.random() * 1000)
-    }));
-
-    // Create workspace first
-    await this.db.run(
-      'INSERT INTO workspaces (id, name, folder_path, state_json) VALUES (?, ?, ?, ?)',
-      ['bench-workspace', 'Benchmark Workspace', '/bench', '{}']
-    );
-
-    // Benchmark bulk inserts with transaction
-    const start = performance.now();
-    
-    await this.db.transaction(async () => {
-      const stmt = await this.db.prepare(
-        'INSERT INTO files (path, workspace_id, size, is_binary, token_count) VALUES (?, ?, ?, ?, ?)'
-      );
-      
-      for (const file of testFiles) {
-        await stmt.run(
-          file.path,
-          file.workspaceId,
-          file.size,
-          file.isBinary ? 1 : 0,
-          file.tokenCount
-        );
-      }
-      
-      await stmt.finalize();
-    });
-
-    const duration = performance.now() - start;
-    
-    this.results.push({
-      operation: 'bulk_insert_10k_files',
-      duration,
-      opsPerSecond: 10_000 / (duration / 1000),
-      details: {
-        totalRecords: 10_000,
-        avgTimePerRecord: duration / 10_000
-      }
-    });
-  }
-
-  private async benchmarkReads() {
-    console.log('Benchmarking READ operations...');
-    
-    // Single record retrieval
-    const singleReadStart = performance.now();
-    for (let i = 0; i < 1000; i++) {
-      await this.db.get(
-        'SELECT * FROM files WHERE path = ? AND workspace_id = ?',
-        [`/test/file${i}.ts`, 'bench-workspace']
-      );
-    }
-    const singleReadDuration = performance.now() - singleReadStart;
-    
-    this.results.push({
-      operation: 'single_record_reads',
-      duration: singleReadDuration,
-      opsPerSecond: 1000 / (singleReadDuration / 1000),
-      details: {
-        queryCount: 1000,
-        avgTimePerQuery: singleReadDuration / 1000
-      }
-    });
-
-    // Batch reads
-    const batchReadStart = performance.now();
-    for (let i = 0; i < 100; i++) {
-      await this.db.all(
-        'SELECT * FROM files WHERE workspace_id = ? LIMIT 100',
-        ['bench-workspace']
-      );
-    }
-    const batchReadDuration = performance.now() - batchReadStart;
-    
-    this.results.push({
-      operation: 'batch_reads_100_records',
-      duration: batchReadDuration,
-      opsPerSecond: 100 / (batchReadDuration / 1000),
-      details: {
-        batchCount: 100,
-        recordsPerBatch: 100,
-        avgTimePerBatch: batchReadDuration / 100
-      }
-    });
-
-    // Complex query with joins
-    const complexQueryStart = performance.now();
-    for (let i = 0; i < 100; i++) {
-      await this.db.all(`
-        SELECT 
-          f.path,
-          f.size,
-          f.token_count,
-          w.name as workspace_name
-        FROM files f
-        JOIN workspaces w ON f.workspace_id = w.id
-        WHERE f.size > ? AND f.is_binary = 0
-        ORDER BY f.token_count DESC
-        LIMIT 50
-      `, [50_000]);
-    }
-    const complexQueryDuration = performance.now() - complexQueryStart;
-    
-    this.results.push({
-      operation: 'complex_queries_with_joins',
-      duration: complexQueryDuration,
-      opsPerSecond: 100 / (complexQueryDuration / 1000),
-      details: {
-        queryCount: 100,
-        avgTimePerQuery: complexQueryDuration / 100
-      }
-    });
-  }
-
-  private async benchmarkTransactions() {
-    console.log('Benchmarking TRANSACTION operations...');
-    
-    // Small transactions
-    const smallTxStart = performance.now();
-    for (let i = 0; i < 100; i++) {
-      await this.db.transaction(async () => {
-        await this.db.run(
-          'UPDATE files SET token_count = ? WHERE path = ?',
-          [Math.floor(Math.random() * 1000), `/test/file${i}.ts`]
-        );
-      });
-    }
-    const smallTxDuration = performance.now() - smallTxStart;
-    
-    this.results.push({
-      operation: 'small_transactions',
-      duration: smallTxDuration,
-      opsPerSecond: 100 / (smallTxDuration / 1000),
-      details: {
-        transactionCount: 100,
-        operationsPerTransaction: 1
-      }
-    });
-
-    // Large transaction
-    const largeTxStart = performance.now();
-    await this.db.transaction(async () => {
-      for (let i = 0; i < 1000; i++) {
-        await this.db.run(
-          'UPDATE files SET size = ? WHERE path = ?',
-          [Math.floor(Math.random() * 100_000), `/test/file${i}.ts`]
-        );
-      }
-    });
-    const largeTxDuration = performance.now() - largeTxStart;
-    
-    this.results.push({
-      operation: 'large_transaction_1k_updates',
-      duration: largeTxDuration,
-      opsPerSecond: 1000 / (largeTxDuration / 1000),
-      details: {
-        updateCount: 1000,
-        avgTimePerUpdate: largeTxDuration / 1000
-      }
-    });
-  }
-
-  private async benchmarkConcurrentReads() {
-    console.log('Benchmarking CONCURRENT operations...');
-    
-    // Concurrent reads
-    const concurrentReadStart = performance.now();
-    const readPromises = Array.from({ length: 100 }, (_, i) =>
-      this.db.get(
-        'SELECT * FROM files WHERE path = ?',
-        [`/test/file${i * 10}.ts`]
-      )
-    );
-    await Promise.all(readPromises);
-    const concurrentReadDuration = performance.now() - concurrentReadStart;
-    
-    this.results.push({
-      operation: 'concurrent_reads_100',
-      duration: concurrentReadDuration,
-      opsPerSecond: 100 / (concurrentReadDuration / 1000),
-      details: {
-        concurrentQueries: 100
-      }
-    });
-
-    // Mixed concurrent operations
-    const mixedStart = performance.now();
-    const mixedPromises = [];
-    
-    // 50 reads
-    for (let i = 0; i < 50; i++) {
-      mixedPromises.push(
-        this.db.get('SELECT * FROM files WHERE path = ?', [`/test/file${i}.ts`])
-      );
-    }
-    
-    // 25 updates
-    for (let i = 0; i < 25; i++) {
-      mixedPromises.push(
-        this.db.run(
-          'UPDATE files SET token_count = ? WHERE path = ?',
-          [Math.floor(Math.random() * 1000), `/test/file${i + 1000}.ts`]
-        )
-      );
-    }
-    
-    // 25 inserts
-    for (let i = 0; i < 25; i++) {
-      mixedPromises.push(
-        this.db.run(
-          'INSERT OR IGNORE INTO preferences (key, value) VALUES (?, ?)',
-          [`pref_${i}`, JSON.stringify({ value: i })]
-        )
-      );
-    }
-    
-    await Promise.all(mixedPromises);
-    const mixedDuration = performance.now() - mixedStart;
-    
-    this.results.push({
-      operation: 'mixed_concurrent_operations',
-      duration: mixedDuration,
-      opsPerSecond: 100 / (mixedDuration / 1000),
-      details: {
-        reads: 50,
-        updates: 25,
-        inserts: 25
-      }
-    });
-  }
-
-  private async benchmarkFileOperations() {
-    console.log('Benchmarking FILE CONTENT operations...');
-    
-    // Prepare content of various sizes
-    const smallContent = 'const x = 1;
'.repeat(10);
-    const mediumContent = 'function test() { return "test"; }
'.repeat(100);
-    const largeContent = 'export class TestClass { constructor() {} }
'.repeat(1000);
-    
-    // Content hashing and deduplication
-    const hashingStart = performance.now();
-    const contents = [smallContent, mediumContent, largeContent];
-    
-    for (let i = 0; i < 100; i++) {
-      for (const content of contents) {
-        const hash = createHash('sha256').update(content).digest('hex');
-        // Hash is computed but not stored - we're only measuring performance
-        void hash;
-      }
-    }
-    const hashingDuration = performance.now() - hashingStart;
-    
-    this.results.push({
-      operation: 'content_hashing',
-      duration: hashingDuration,
-      opsPerSecond: 300 / (hashingDuration / 1000),
-      details: {
-        totalHashes: 300,
-        contentSizes: ['small', 'medium', 'large']
-      }
-    });
-
-    // File content storage
-    const storageStart = performance.now();
-    for (let i = 0; i < 100; i++) {
-      const content = contents[i % 3];
-      const hash = createHash('sha256').update(content).digest('hex');
-      
-      await this.db.run(
-        'INSERT OR IGNORE INTO file_contents (hash, content, original_size, compressed_size, compression_ratio) VALUES (?, ?, ?, ?, ?)',
-        [hash, Buffer.from(content), content.length, content.length * 0.3, 0.3]
-      );
-    }
-    const storageDuration = performance.now() - storageStart;
-    
-    this.results.push({
-      operation: 'file_content_storage',
-      duration: storageDuration,
-      opsPerSecond: 100 / (storageDuration / 1000),
-      details: {
-        operations: 100
-      }
-    });
-  }
-
-  private async benchmarkWorkspaceOperations() {
-    console.log('Benchmarking WORKSPACE operations...');
-    
-    // Create workspaces
-    const createStart = performance.now();
-    const workspaceIds = [];
-    for (let i = 0; i < 50; i++) {
-      const id = `workspace-${i}`;
-      await this.db.run(
-        'INSERT INTO workspaces (id, name, folder_path, state_json) VALUES (?, ?, ?, ?)',
-        [id, `Workspace ${i}`, `/workspace/${i}`, JSON.stringify({
-          selectedFiles: Array.from({ length: 20 }, (_, j) => `/file${j}.ts`),
-          expandedNodes: { '/src': true, '/tests': true },
-          userInstructions: 'Test instructions',
-          customPrompts: { system: 'Test prompt' }
-        })]
-      );
-      workspaceIds.push(id);
-    }
-    const createDuration = performance.now() - createStart;
-    
-    this.results.push({
-      operation: 'workspace_creation',
-      duration: createDuration,
-      opsPerSecond: 50 / (createDuration / 1000),
-      details: {
-        workspaceCount: 50
-      }
-    });
-
-    // Load workspaces
-    const loadStart = performance.now();
-    for (const id of workspaceIds) {
-      await this.db.get('SELECT * FROM workspaces WHERE id = ?', [id]);
-    }
-    const loadDuration = performance.now() - loadStart;
-    
-    this.results.push({
-      operation: 'workspace_loading',
-      duration: loadDuration,
-      opsPerSecond: 50 / (loadDuration / 1000),
-      details: {
-        workspaceCount: 50
-      }
-    });
-
-    // Update workspace state
-    const updateStart = performance.now();
-    for (const id of workspaceIds) {
-      await this.db.run(
-        'UPDATE workspaces SET state_json = ?, last_accessed = strftime("%s", "now") WHERE id = ?',
-        [JSON.stringify({
-          selectedFiles: Array.from({ length: 50 }, (_, j) => `/updated/file${j}.ts`),
-          expandedNodes: { '/src': true, '/tests': true, '/docs': true },
-          userInstructions: 'Updated instructions with more content',
-          customPrompts: { system: 'Updated prompt', role: 'Assistant' }
-        }), id]
-      );
-    }
-    const updateDuration = performance.now() - updateStart;
-    
-    this.results.push({
-      operation: 'workspace_state_updates',
-      duration: updateDuration,
-      opsPerSecond: 50 / (updateDuration / 1000),
-      details: {
-        updateCount: 50
-      }
-    });
-  }
-
-  private generateReport() {
-    console.log('
=== PasteFlow Database Performance Report ===
');
-    
-    const report = {
-      summary: {
-        totalBenchmarks: this.results.length,
-        totalDuration: this.results.reduce((sum, r) => sum + r.duration, 0),
-        timestamp: new Date().toISOString()
-      },
-      results: this.results.map(r => ({
-        ...r,
-        durationMs: Math.round(r.duration * 100) / 100,
-        opsPerSecond: Math.round(r.opsPerSecond * 100) / 100
-      })),
-      performance: (() => {
-        let fastestOperation = this.results[0];
-        let slowestOperation = this.results[0];
-        
-        for (const r of this.results) {
-          if (r.opsPerSecond > fastestOperation.opsPerSecond) {
-            fastestOperation = r;
-          }
-          if (r.opsPerSecond < slowestOperation.opsPerSecond) {
-            slowestOperation = r;
-          }
-        }
-        
-        return {
-          fastestOperation,
-          slowestOperation
-        };
-      })()
-    };
-
-    // Print summary
-    console.log('Operation Summary:');
-    console.log('â”€'.repeat(80));
-    console.log(
-      'Operation'.padEnd(35) +
-      'Duration (ms)'.padStart(15) +
-      'Ops/Second'.padStart(15) +
-      'Details'.padStart(15)
-    );
-    console.log('â”€'.repeat(80));
-    
-    for (const result of this.results) {
-      console.log(
-        result.operation.padEnd(35) +
-        result.duration.toFixed(2).padStart(15) +
-        result.opsPerSecond.toFixed(2).padStart(15) +
-        (result.details ? ' âœ“' : '').padStart(15)
-      );
-    }
-    
-    console.log('â”€'.repeat(80));
-    console.log('
Performance Targets:');
-    console.log(`âœ“ Database initialization: <100ms (actual: ~${this.results[0]?.duration.toFixed(0)}ms)`);
-    console.log(`âœ“ Simple queries: <5ms (actual: ~${(this.results.find(r => r.operation === 'single_record_reads')?.duration || 0) / 1000}ms per query)`);
-    console.log(`âœ“ Complex queries: <50ms (actual: ~${(this.results.find(r => r.operation === 'complex_queries_with_joins')?.details?.avgTimePerQuery as number || 0).toFixed(2)}ms)`);
-    console.log(`âœ“ Concurrent operations: 100+ simultaneous (tested: 100 concurrent)`);
-    
-    return report;
-  }
-}
-
-// Run benchmarks if called directly
-if (import.meta.url === `file://${process.argv[1]}`) {
-  const benchmarks = new DatabaseBenchmarks();
-  try {
-    await benchmarks.runAllBenchmarks();
-    console.log('
Benchmark complete!');
-    // eslint-disable-next-line unicorn/no-process-exit
-    process.exit(0);
-  } catch (error) {
-    console.error('Benchmark error:', error);
-    // eslint-disable-next-line unicorn/no-process-exit
-    process.exit(1);
-  }
-}
\ No newline at end of file
diff --git a/src/main/db/__tests__/connection-pool-test.ts b/src/main/db/__tests__/connection-pool-test.ts
deleted file mode 100644
index 3492069..0000000
--- a/src/main/db/__tests__/connection-pool-test.ts
+++ /dev/null
@@ -1,386 +0,0 @@
-import * as fs from 'node:fs/promises';
-import * as path from 'node:path';
-import * as os from 'node:os';
-
-import { ConnectionPool } from '../connection-pool';
-import { PooledDatabase } from '../pooled-database';
-import { PooledDatabaseBridge } from '../pooled-database-bridge';
-import { TEST_CONFIG, HIGH_LOAD_CONFIG } from '../pool-config';
-
-// Test constants
-const TEST_WORKSPACE_NAME = 'test-workspace';
-
-// Mock electron module
-const mockApp = {
-  getPath: jest.fn()
-};
-
-jest.mock('electron', () => ({
-  app: mockApp
-}));
-
-describe('Connection Pool', () => {
-  let tempDir: string;
-  let dbPath: string;
-
-  beforeEach(async () => {
-    tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'pool-test-'));
-    dbPath = path.join(tempDir, 'test.db');
-  });
-
-  afterEach(async () => {
-    await fs.rm(tempDir, { recursive: true, force: true });
-  });
-
-  describe('ConnectionPool Core Functionality', () => {
-    test('should initialize with minimum read connections', async () => {
-      const pool = new ConnectionPool(dbPath, {
-        minReadConnections: 3,
-        maxReadConnections: 10
-      });
-
-      await pool.initialize();
-
-      const stats = pool.getStats();
-      expect(stats.totalConnections).toBeGreaterThanOrEqual(4); // 3 read + 1 write
-      expect(stats.idleConnections).toBeGreaterThanOrEqual(3);
-
-      await pool.shutdown();
-    });
-
-    test('should handle concurrent read operations efficiently', async () => {
-      const pool = new ConnectionPool(dbPath, {
-        minReadConnections: 5,
-        maxReadConnections: 10
-      });
-
-      await pool.initialize();
-
-      // Create test table
-      await pool.executeQueryRun('CREATE TABLE test_concurrent (id INTEGER, value TEXT)');
-      
-      // Insert test data
-      for (let i = 0; i < 100; i++) {
-        await pool.executeQueryRun('INSERT INTO test_concurrent VALUES (?, ?)', [i, `value_${i}`]);
-      }
-
-      // Execute 50 concurrent read operations
-      const promises = Array.from({ length: 50 }, (_, i) =>
-        pool.executeQuery<{ id: number; value: string }>(
-          'SELECT * FROM test_concurrent WHERE id = ?',
-          [i % 100],
-          'read'
-        )
-      );
-
-      const results = await Promise.all(promises);
-      expect(results).toHaveLength(50);
-      expect(results.every(r => r && typeof r.id === 'number')).toBe(true);
-
-      await pool.shutdown();
-    });
-
-    test('should queue requests when pool is exhausted', async () => {
-      const pool = new ConnectionPool(dbPath, {
-        minReadConnections: 2,
-        maxReadConnections: 2,
-        acquireTimeout: 5000
-      });
-
-      await pool.initialize();
-
-      // Create a slow query to hold connections
-      await pool.executeQueryRun('CREATE TABLE test_queue (id INTEGER)');
-
-      const slowPromises = [
-        pool.executeQuery('SELECT 1, (SELECT count(*) FROM test_queue)', [], 'read'),
-        pool.executeQuery('SELECT 2, (SELECT count(*) FROM test_queue)', [], 'read')
-      ];
-
-      // These should be queued
-      const queuedPromises = [
-        pool.executeQuery('SELECT 3', [], 'read'),
-        pool.executeQuery('SELECT 4', [], 'read')
-      ];
-
-      const allResults = await Promise.all([...slowPromises, ...queuedPromises]);
-      expect(allResults).toHaveLength(4);
-
-      await pool.shutdown();
-    });
-
-    test('should handle connection failures gracefully', async () => {
-      const pool = new ConnectionPool('/invalid/path/test.db', {
-        minReadConnections: 1,
-        maxReadConnections: 3
-      });
-
-      await expect(pool.initialize()).rejects.toThrow();
-    });
-  });
-
-  describe('PooledDatabase Features', () => {
-    test('should cache read queries effectively', async () => {
-      const db = new PooledDatabase(dbPath, {
-        enableQueryCache: true,
-        queryCacheSize: 100,
-        queryCacheTTL: 60_000
-      });
-
-      await db.initialize();
-
-      // Create test data
-      await db.run('CREATE TABLE test_cache (id INTEGER PRIMARY KEY, name TEXT)');
-      await db.run('INSERT INTO test_cache VALUES (1, ?)', ['test_name']);
-
-      // First query - cache miss
-      const result1 = await db.get<{ id: number; name: string }>('SELECT * FROM test_cache WHERE id = 1');
-      expect(result1?.name).toBe('test_name');
-
-      // Second query - should be cache hit
-      const result2 = await db.get<{ id: number; name: string }>('SELECT * FROM test_cache WHERE id = 1');
-      expect(result2?.name).toBe('test_name');
-
-      const cacheStats = db.getCacheStats();
-      expect(cacheStats.totalRequests).toBe(2);
-      expect(cacheStats.totalHits).toBe(1);
-      expect(cacheStats.hitRate).toBe(50);
-
-      await db.shutdown();
-    });
-
-    test('should invalidate cache on write operations', async () => {
-      const db = new PooledDatabase(dbPath, {
-        enableQueryCache: true,
-        queryCacheSize: 100,
-        queryCacheTTL: 60_000
-      });
-
-      await db.initialize();
-
-      // Create and query data
-      await db.run('CREATE TABLE test_invalidate (id INTEGER, value TEXT)');
-      await db.run('INSERT INTO test_invalidate VALUES (1, ?)', ['original']);
-
-      // Cache the query
-      const result1 = await db.get<{ value: string }>('SELECT value FROM test_invalidate WHERE id = 1');
-      expect(result1?.value).toBe('original');
-
-      // Update data (should invalidate cache)
-      await db.run('UPDATE test_invalidate SET value = ? WHERE id = 1', ['updated']);
-
-      // Query again - should see updated value
-      const result2 = await db.get<{ value: string }>('SELECT value FROM test_invalidate WHERE id = 1');
-      expect(result2?.value).toBe('updated');
-
-      await db.shutdown();
-    });
-
-    test('should handle transactions with retries', async () => {
-      const db = new PooledDatabase(dbPath, {
-        minReadConnections: 1,
-        maxReadConnections: 2
-      });
-
-      await db.initialize();
-
-      await db.run('CREATE TABLE test_transaction (id INTEGER PRIMARY KEY, counter INTEGER DEFAULT 0)');
-      await db.run('INSERT INTO test_transaction (id) VALUES (1)');
-
-      // Simulate concurrent transactions
-      const promises = Array.from({ length: 10 }, async () => {
-        return db.transaction(async (txDb) => {
-          const current = await txDb.get<{ counter: number }>('SELECT counter FROM test_transaction WHERE id = 1');
-          const newValue = (current?.counter || 0) + 1;
-          await txDb.run('UPDATE test_transaction SET counter = ? WHERE id = 1', [newValue]);
-          return newValue;
-        });
-      });
-
-      const results = await Promise.all(promises);
-      expect(results).toHaveLength(10);
-
-      // Verify final state
-      const final = await db.get<{ counter: number }>('SELECT counter FROM test_transaction WHERE id = 1');
-      expect(final?.counter).toBe(10);
-
-      await db.shutdown();
-    });
-  });
-
-  describe('PooledDatabaseBridge Integration', () => {
-    test('should handle workspace operations with pooling', async () => {
-      // Mock app.getPath for testing
-      mockApp.getPath.mockReturnValue(tempDir);
-
-      const bridge = new PooledDatabaseBridge(TEST_CONFIG);
-      await bridge.initialize();
-
-      // Test workspace operations
-      const workspace = await bridge.createWorkspace(TEST_WORKSPACE_NAME, '/test/path', {
-        selectedFiles: [{ path: '/test/file.ts' }],
-        expandedNodes: { '/test': true }
-      });
-
-      expect(workspace.name).toBe(TEST_WORKSPACE_NAME);
-      expect(workspace.folderPath).toBe('/test/path');
-
-      // Test list operation
-      const workspaces = await bridge.listWorkspaces();
-      expect(workspaces).toHaveLength(1);
-      expect(workspaces[0].name).toBe(TEST_WORKSPACE_NAME);
-
-      // Test update operation
-      await bridge.updateWorkspace(TEST_WORKSPACE_NAME, {
-        selectedFolder: null,
-        allFiles: [],
-        selectedFiles: [{ path: '/test/file.ts' }, { path: '/test/file2.ts' }],
-        expandedNodes: {},
-        sortOrder: 'name',
-        searchTerm: '',
-        fileTreeMode: 'none',
-        exclusionPatterns: [],
-        userInstructions: '',
-        tokenCounts: {},
-        customPrompts: {
-          systemPrompts: [],
-          rolePrompts: []
-        }
-      });
-
-      const updated = await bridge.getWorkspace(TEST_WORKSPACE_NAME);
-      expect(updated.selectedFiles).toHaveLength(2);
-
-      await bridge.close();
-
-      // Clear mock
-      mockApp.getPath.mockClear();
-    });
-
-    test('should provide performance metrics', async () => {
-      // Mock app.getPath for testing
-      mockApp.getPath.mockReturnValue(tempDir);
-
-      const bridge = new PooledDatabaseBridge({
-        ...TEST_CONFIG,
-        enablePerformanceMonitoring: true
-      });
-
-      await bridge.initialize();
-
-      // Perform some operations
-      await bridge.createWorkspace('perf-test', '/test', {});
-      await bridge.getWorkspace('perf-test');
-      await bridge.setPreference('test-key', 'test-value');
-      await bridge.getPreference('test-key');
-
-      const stats = bridge.getStats();
-      const performance = bridge.getPerformanceMetrics();
-
-      expect(stats).toBeTruthy();
-      expect(stats!.totalQueries).toBeGreaterThan(0);
-      expect(performance).toBeTruthy();
-      expect(performance!.queriesPerSecond).toBeGreaterThanOrEqual(0);
-
-      await bridge.close();
-
-      // Clear mock
-      mockApp.getPath.mockClear();
-    });
-
-    test('should handle high-load scenarios', async () => {
-      // Mock app.getPath for testing
-      mockApp.getPath.mockReturnValue(tempDir);
-
-      const bridge = new PooledDatabaseBridge(HIGH_LOAD_CONFIG);
-      await bridge.initialize();
-
-      // Simulate high-load scenario
-      const operations = Array.from({ length: 100 }, async (_, i) => {
-        const workspaceName = `workspace-${i}`;
-        await bridge.createWorkspace(workspaceName, `/test/${i}`, {
-          selectedFiles: Array.from({ length: 20 }, (_, j) => ({ path: `/file${j}.ts` }))
-        });
-        
-        const workspace = await bridge.getWorkspace(workspaceName);
-        expect(workspace.name).toBe(workspaceName);
-        
-        await bridge.setPreference(`pref-${i}`, `value-${i}`);
-        const prefValue = await bridge.getPreference(`pref-${i}`);
-        expect(prefValue).toBe(`value-${i}`);
-      });
-
-      await Promise.all(operations);
-
-      const stats = bridge.getStats();
-      expect(stats!.totalQueries).toBeGreaterThan(200); // At least 2 queries per operation
-
-      const workspaces = await bridge.listWorkspaces();
-      expect(workspaces).toHaveLength(100);
-
-      await bridge.close();
-
-      // Clear mock
-      mockApp.getPath.mockClear();
-    });
-  });
-
-  describe('Error Handling and Recovery', () => {
-    test('should recover from connection failures', async () => {
-      const pool = new ConnectionPool(dbPath, {
-        minReadConnections: 2,
-        maxReadConnections: 5,
-        healthCheckInterval: 1000 // 1 second for fast testing
-      });
-
-      await pool.initialize();
-
-      // Force a few operations to ensure pool is working
-      await pool.executeQueryRun('CREATE TABLE test_recovery (id INTEGER)');
-      await pool.executeQueryRun('INSERT INTO test_recovery VALUES (1)');
-
-      const result = await pool.executeQuery<{ id: number }>('SELECT * FROM test_recovery');
-      expect(result?.id).toBe(1);
-
-      await pool.shutdown();
-    });
-
-    test('should timeout long-running operations', async () => {
-      const pool = new ConnectionPool(dbPath, {
-        minReadConnections: 1,
-        maxReadConnections: 1,
-        acquireTimeout: 1000 // 1 second timeout
-      });
-
-      await pool.initialize();
-
-      // Start a long-running operation that holds the connection
-      const longOperation = pool.executeQuery('SELECT 1', [], 'read');
-
-      // Try to acquire another connection - should timeout
-      await expect(
-        pool.executeQuery('SELECT 2', [], 'read')
-      ).rejects.toThrow(/timeout/i);
-
-      await longOperation; // Clean up
-      await pool.shutdown();
-    });
-  });
-
-  describe('Configuration Validation', () => {
-    test('should validate pool configuration constraints', () => {
-      expect(() => {
-        new ConnectionPool(dbPath, {
-          minReadConnections: 0 // Invalid
-        });
-      }).toThrow();
-
-      expect(() => {
-        new ConnectionPool(dbPath, {
-          minReadConnections: 5,
-          maxReadConnections: 3 // Invalid: max < min
-        });
-      }).toThrow();
-    });
-  });
-});
\ No newline at end of file
diff --git a/src/main/db/__tests__/security-test.ts b/src/main/db/__tests__/security-test.ts
deleted file mode 100644
index b2baa4c..0000000
--- a/src/main/db/__tests__/security-test.ts
+++ /dev/null
@@ -1,359 +0,0 @@
-import * as fs from 'node:fs/promises';
-import * as path from 'node:path';
-import * as os from 'node:os';
-
-import * as keytar from 'keytar';
-
-import { AsyncDatabase } from '../async-database';
-import { SecureDatabase } from '../secure-database';
-
-describe('Database Security', () => {
-  let tempDir: string;
-  let dbPath: string;
-  const SERVICE_NAME = 'com.pasteflow.app';
-  const ACCOUNT_NAME = 'db-encryption-key';
-
-  beforeEach(async () => {
-    // Create temporary directory
-    tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'pasteflow-security-test-'));
-    dbPath = path.join(tempDir, 'secure-test.db');
-    
-    // Clear any existing keychain entry for tests
-    await keytar.deletePassword(SERVICE_NAME, ACCOUNT_NAME).catch(() => {});
-  });
-
-  afterEach(async () => {
-    // Clean up
-    await keytar.deletePassword(SERVICE_NAME, ACCOUNT_NAME).catch(() => {});
-    await fs.rm(tempDir, { recursive: true, force: true }).catch(() => {});
-  });
-
-  describe('Encryption key management', () => {
-    it('should generate and store encryption key on first run', async () => {
-      // Verify no key exists initially
-      const initialKey = await keytar.getPassword(SERVICE_NAME, ACCOUNT_NAME);
-      expect(initialKey).toBeNull();
-
-      // Create secure database
-      const db = await SecureDatabase.create(dbPath);
-
-      // Verify key was created and stored
-      const storedKey = await keytar.getPassword(SERVICE_NAME, ACCOUNT_NAME);
-      expect(storedKey).toBeDefined();
-      expect(storedKey).not.toBeNull();
-      expect(storedKey?.length).toBeGreaterThan(0);
-
-      // Verify key is valid base64
-      expect(() => Buffer.from(storedKey!, 'base64')).not.toThrow();
-
-      await db.close();
-    });
-
-    it('should reuse existing encryption key on subsequent runs', async () => {
-      // Create first instance
-      const db1 = await SecureDatabase.create(dbPath);
-      const key1 = await keytar.getPassword(SERVICE_NAME, ACCOUNT_NAME);
-      await db1.close();
-
-      // Create second instance
-      const db2 = await SecureDatabase.create(dbPath);
-      const key2 = await keytar.getPassword(SERVICE_NAME, ACCOUNT_NAME);
-      await db2.close();
-
-      // Keys should be identical
-      expect(key2).toBe(key1);
-    });
-
-    it('should derive unique device-specific keys', async () => {
-      // This test verifies that the derived key includes device-specific information
-      const db = await SecureDatabase.create(dbPath);
-      
-      // Create test data
-      const testData = { test: 'sensitive data' };
-      await db.setPreference('test-key', testData, true);
-      
-      // Retrieve and verify
-      const retrieved = await db.getPreference('test-key');
-      expect(retrieved).toEqual(testData);
-      
-      await db.close();
-    });
-  });
-
-  describe('Database encryption', () => {
-    it('should encrypt database contents with SQLCipher', async () => {
-      const db = await SecureDatabase.create(dbPath);
-      
-      // Insert sensitive data
-      const workspaceId = await db.createWorkspace(
-        'Secure Workspace',
-        '/secure/path',
-        { apiKey: 'super-secret-key', tokens: ['token1', 'token2'] }
-      );
-
-      // Save file content
-      await db.saveFileContent(
-        workspaceId,
-        '/secure/file.ts',
-        'const secret = "confidential information";',
-        10
-      );
-
-      await db.close();
-
-      // Try to read database file directly (should be encrypted)
-      const rawContent = await fs.readFile(dbPath);
-      const contentString = rawContent.toString('utf8', 0, 1000);
-      
-      // Should not contain readable data
-      expect(contentString).not.toContain('Secure Workspace');
-      expect(contentString).not.toContain('super-secret-key');
-      expect(contentString).not.toContain('confidential information');
-      
-      // Should look like encrypted/binary data
-      // eslint-disable-next-line no-control-regex
-      expect(contentString).toMatch(/[ --Ã¿]/);
-    });
-
-    it('should fail to access encrypted database without proper key', async () => {
-      // Create and populate encrypted database
-      const db1 = await SecureDatabase.create(dbPath);
-      await db1.createWorkspace('Test', '/test', {});
-      await db1.close();
-
-      // Try to access with wrong key by manipulating keychain
-      const originalKey = await keytar.getPassword(SERVICE_NAME, ACCOUNT_NAME);
-      await keytar.setPassword(SERVICE_NAME, ACCOUNT_NAME, 'wrong-key-base64');
-
-      // Should fail to access
-      await expect(SecureDatabase.create(dbPath)).rejects.toThrow();
-
-      // Restore original key
-      await keytar.setPassword(SERVICE_NAME, ACCOUNT_NAME, originalKey!);
-    });
-  });
-
-  describe('Preference encryption', () => {
-    it('should encrypt sensitive preferences', async () => {
-      const db = await SecureDatabase.create(dbPath);
-      
-      // Store sensitive data
-      const sensitiveData = {
-        apiKey: 'sk-1234567890abcdef',
-        refreshToken: 'refresh-token-value',
-        credentials: {
-          username: 'user@example.com',
-          password: 'secure-password'
-        }
-      };
-
-      await db.setPreference('auth-config', sensitiveData, true);
-
-      // Verify retrieval works
-      const retrieved = await db.getPreference('auth-config');
-      expect(retrieved).toEqual(sensitiveData);
-
-      // Check raw database storage
-      const rawDb = new AsyncDatabase(dbPath);
-      const rawPref = await rawDb.get<{ value: string; encrypted: number }>(
-        'SELECT value, encrypted FROM preferences WHERE key = ?',
-        ['auth-config']
-      );
-
-      // Should be marked as encrypted
-      expect(rawPref?.encrypted).toBe(1);
-      
-      // Value should not contain readable sensitive data
-      expect(rawPref?.value).not.toContain('sk-1234567890abcdef');
-      expect(rawPref?.value).not.toContain('secure-password');
-      
-      // Should look like encrypted data (format: iv:encrypted)
-      expect(rawPref?.value).toMatch(/^[\da-f]{32}:[\da-f]+$/);
-
-      await rawDb.close();
-      await db.close();
-    });
-
-    it('should store non-sensitive preferences in plain text', async () => {
-      const db = await SecureDatabase.create(dbPath);
-      
-      // Store non-sensitive data
-      const settings = {
-        theme: 'dark',
-        fontSize: 14,
-        autoSave: true
-      };
-
-      await db.setPreference('ui-settings', settings, false);
-
-      // Verify retrieval
-      const retrieved = await db.getPreference('ui-settings');
-      expect(retrieved).toEqual(settings);
-
-      // Check raw storage
-      const rawDb = new AsyncDatabase(dbPath);
-      const rawPref = await rawDb.get<{ value: string; encrypted: number }>(
-        'SELECT value, encrypted FROM preferences WHERE key = ?',
-        ['ui-settings']
-      );
-
-      // Should not be encrypted
-      expect(rawPref?.encrypted).toBe(0);
-      
-      // Value should be readable JSON
-      expect(JSON.parse(rawPref?.value || '{}')).toEqual(settings);
-
-      await rawDb.close();
-      await db.close();
-    });
-  });
-
-  describe('File content security', () => {
-    it('should compress and deduplicate file contents', async () => {
-      const db = await SecureDatabase.create(dbPath);
-      const workspaceId = await db.createWorkspace('Test', '/test', {});
-      
-      // Same content in different files
-      const duplicateContent = 'export function testFunction() {
  return "test";
}
'.repeat(100);
-      
-      // Save same content to multiple files
-      await db.saveFileContent(workspaceId, '/file1.ts', duplicateContent, 50);
-      await db.saveFileContent(workspaceId, '/file2.ts', duplicateContent, 50);
-      await db.saveFileContent(workspaceId, '/file3.ts', duplicateContent, 50);
-
-      // Check deduplication
-      const rawDb = new AsyncDatabase(dbPath);
-      
-      // Should have 3 file entries
-      const files = await rawDb.all<{ content_hash: string }>(
-        'SELECT content_hash FROM files WHERE workspace_id = ?',
-        [workspaceId]
-      );
-      expect(files).toHaveLength(3);
-      
-      // All should have same hash
-      const hashes = files.map(f => f.content_hash);
-      expect(new Set(hashes).size).toBe(1);
-
-      // Should have only 1 content entry
-      const contents = await rawDb.all<{ 
-        hash: string;
-        original_size: number;
-        compressed_size: number;
-        compression_ratio: number;
-      }>('SELECT * FROM file_contents');
-      expect(contents).toHaveLength(1);
-      
-      // Verify compression
-      const content = contents[0];
-      expect(content.compressed_size).toBeLessThan(content.original_size);
-      expect(content.compression_ratio).toBeLessThan(1);
-      expect(content.compression_ratio).toBeGreaterThan(0);
-
-      await rawDb.close();
-      await db.close();
-    });
-
-    it('should correctly retrieve deduplicated content', async () => {
-      const db = await SecureDatabase.create(dbPath);
-      const workspaceId = await db.createWorkspace('Test', '/test', {});
-      
-      // Different contents
-      const content1 = 'const a = 1;
';
-      const content2 = 'const b = 2;
';
-      const content3 = content1; // Duplicate of content1
-      
-      // Save files
-      await db.saveFileContent(workspaceId, '/file1.ts', content1, 5);
-      await db.saveFileContent(workspaceId, '/file2.ts', content2, 5);
-      await db.saveFileContent(workspaceId, '/file3.ts', content3, 5);
-
-      // Retrieve and verify
-      const retrieved1 = await db.getFileContent(workspaceId, '/file1.ts');
-      const retrieved2 = await db.getFileContent(workspaceId, '/file2.ts');
-      const retrieved3 = await db.getFileContent(workspaceId, '/file3.ts');
-
-      expect(retrieved1).toBe(content1);
-      expect(retrieved2).toBe(content2);
-      expect(retrieved3).toBe(content3);
-
-      // Verify deduplication worked
-      const rawDb = new AsyncDatabase(dbPath);
-      const contentCount = await rawDb.get<{ count: number }>(
-        'SELECT COUNT(*) as count FROM file_contents'
-      );
-      expect(contentCount?.count).toBe(2); // Only 2 unique contents
-
-      await rawDb.close();
-      await db.close();
-    });
-  });
-
-  describe('Access control', () => {
-    it('should validate workspace access boundaries', async () => {
-      const db = await SecureDatabase.create(dbPath);
-      
-      // Create two workspaces
-      const workspace1 = await db.createWorkspace('Workspace 1', '/workspace1', {});
-      const workspace2 = await db.createWorkspace('Workspace 2', '/workspace2', {});
-
-      // Save content to workspace1
-      await db.saveFileContent(workspace1, '/secret.ts', 'secret data', 10);
-
-      // Try to access with wrong workspace ID
-      const content = await db.getFileContent(workspace2, '/secret.ts');
-      expect(content).toBeNull();
-
-      // Correct workspace ID should work
-      const correctContent = await db.getFileContent(workspace1, '/secret.ts');
-      expect(correctContent).toBe('secret data');
-
-      await db.close();
-    });
-
-    it('should enforce unique workspace names', async () => {
-      const db = await SecureDatabase.create(dbPath);
-      
-      // Create first workspace
-      await db.createWorkspace('Unique Name', '/path1', {});
-
-      // Try to create another with same name
-      await expect(
-        db.createWorkspace('Unique Name', '/path2', {})
-      ).rejects.toThrow('UNIQUE constraint failed');
-
-      await db.close();
-    });
-  });
-
-  describe('Audit logging', () => {
-    it('should track critical operations in audit log', async () => {
-      const db = await SecureDatabase.create(dbPath);
-      
-      // Perform operations that should be audited
-      const workspaceId = await db.createWorkspace('Audited Workspace', '/audit', {});
-      await db.updateWorkspace(workspaceId, { modified: true });
-      await db.deleteWorkspace(workspaceId);
-
-      // Check audit log
-      const rawDb = db.database;
-      const auditEntries = await rawDb.all<{
-        operation: string;
-        table_name: string;
-        record_id: string;
-        timestamp: number;
-      }>('SELECT * FROM audit_log ORDER BY timestamp');
-
-      // Should have entries for critical operations
-      expect(auditEntries.length).toBeGreaterThan(0);
-      
-      // Verify audit entries contain expected information
-      const operations = auditEntries.map(e => e.operation);
-      expect(operations).toContain('INSERT');
-      expect(operations).toContain('UPDATE');
-      expect(operations).toContain('DELETE');
-
-      await db.close();
-    });
-  });
-});
\ No newline at end of file
diff --git a/src/main/db/database-bridge.js b/src/main/db/database-bridge.js
index e7b7409..70fb874 100644
--- a/src/main/db/database-bridge.js
+++ b/src/main/db/database-bridge.js
@@ -1,7 +1,8 @@
 const path = require('path');
 const { app } = require('electron');
 const { PasteFlowDatabase } = require('./database-implementation.js');
-const { retryConnection, executeWithRetry, retryUtility } = require('./retry-utils.js');
+// Use compiled TypeScript version of retry-utils
+const { retryConnection, executeWithRetry, retryUtility } = require('../../../build/main/main/db/retry-utils.js');
 
 /**
  * Async wrapper bridge for PasteFlowDatabase with initialization management.
diff --git a/src/main/db/database-implementation.js b/src/main/db/database-implementation.js
index 0ae3389..1e7e0e9 100644
--- a/src/main/db/database-implementation.js
+++ b/src/main/db/database-implementation.js
@@ -2,7 +2,8 @@ const Database = require('better-sqlite3');
 const path = require('path');
 const fs = require('fs');
 const { app } = require('electron');
-const { retryTransaction, retryConnection, executeWithRetry } = require('./retry-utils.js');
+// Use compiled TypeScript version of retry-utils
+const { retryTransaction, retryConnection, executeWithRetry } = require('../../../build/main/main/db/retry-utils.js');
 
 /**
  * SQLite database implementation for PasteFlow workspace and preference management.
diff --git a/src/main/db/database-manager.ts b/src/main/db/database-manager.ts
deleted file mode 100644
index 0406e4f..0000000
--- a/src/main/db/database-manager.ts
+++ /dev/null
@@ -1,237 +0,0 @@
-import * as path from 'node:path';
-import { randomUUID } from 'node:crypto';
-
-import { app, BrowserWindow } from 'electron';
-
-import { SecureIpcLayer } from '../ipc/secure-ipc';
-import { StateHandlers } from '../handlers/state-handlers';
-import { countTokens } from '../utils/token-utils';
-
-import { SecureDatabase } from './secure-database';
-
-interface FileSaveInput {
-  workspaceId: string;
-  filePath: string;
-  content: string;
-  tokenCount: number;
-}
-
-interface PromptListInput {
-  type?: 'system' | 'role';
-}
-
-interface PromptCreateInput {
-  type: 'system' | 'role';
-  name: string;
-  content: string;
-  tokenCount?: number;
-  isActive?: boolean;
-}
-
-interface PromptUpdateInput {
-  id: string;
-  name: string;
-  content: string;
-  tokenCount?: number;
-  isActive?: boolean;
-  type?: 'system' | 'role';
-}
-
-interface PromptDeleteInput {
-  id: string;
-}
-
-export class DatabaseManager {
-  private db!: SecureDatabase;
-  private ipc!: SecureIpcLayer;
-  private static instance: DatabaseManager;
-
-  private constructor() {}
-
-  static getInstance(): DatabaseManager {
-    if (!DatabaseManager.instance) {
-      DatabaseManager.instance = new DatabaseManager();
-    }
-    return DatabaseManager.instance;
-  }
-
-  async initialize() {
-    // Initialize database
-    const userDataPath = app.getPath('userData');
-    const dbPath = path.join(userDataPath, 'pasteflow.db');
-    
-    console.log('Initializing PasteFlow database at:', dbPath);
-    this.db = await SecureDatabase.create(dbPath);
-    
-    // Initialize IPC layer
-    this.ipc = new SecureIpcLayer();
-    
-    // Initialize state handlers (they register their own IPC handlers)
-    new StateHandlers(this.db, this.ipc);
-    
-    // Wire up legacy IPC handlers to database operations
-    this.setupHandlers();
-    
-    console.log('Database and IPC layer initialized successfully');
-  }
-
-  private setupHandlers() {
-    // Workspace & file-content & prefs are handled by StateHandlers.
-
-    this.ipc.setHandler('/file/save', async (input: unknown) => {
-      const validatedInput = input as FileSaveInput; // already Zod-validated by SecureIpcLayer
-      // Ensure tokenCount exists even if omitted by caller
-      const tokenCount =
-        validatedInput.tokenCount ?? countTokens(validatedInput.content);
-      await this.db.saveFileContent(
-        validatedInput.workspaceId,
-        validatedInput.filePath,
-        validatedInput.content,
-        tokenCount
-      );
-      return true;
-    });
-
-    // Preferences are handled by StateHandlers (with encryption/JSON handling).
-
-    // Prompt handlers
-    this.ipc.setHandler('/prompt/list', async (input: unknown) => {
-      const validatedInput = input as PromptListInput; // Zod validated
-      const rows = validatedInput.type
-        ? await this.db.database.all<{
-            id: string; type: string; name: string; content: string;
-            token_count: number | null; is_active: number; created_at: number; updated_at: number;
-          }>('SELECT * FROM prompts WHERE is_active = 1 AND type = ?', [validatedInput.type])
-        : await this.db.database.all<{
-            id: string;
-            type: string;
-            name: string;
-            content: string;
-            token_count: number | null;
-            is_active: number;
-            created_at: number;
-            updated_at: number;
-          }>('SELECT * FROM prompts WHERE is_active = 1');
-
-      return rows
-        .map(p => ({
-          id: p.id,
-          type: p.type as 'system' | 'role',
-          name: p.name,
-          content: p.content,
-          tokenCount: p.token_count || undefined,
-          isActive: p.is_active === 1,
-          createdAt: p.created_at,
-          updatedAt: p.updated_at
-        }));
-    });
-
-    this.ipc.setHandler('/prompt/create', async (input: unknown) => {
-      const validatedInput = input as PromptCreateInput;
-      const id = randomUUID();
-      const tokenCount = validatedInput.tokenCount || countTokens(validatedInput.content);
-      
-      await this.db.database.run(
-        `INSERT INTO prompts (id, type, name, content, token_count, is_active)
-         VALUES (?, ?, ?, ?, ?, ?)`,
-        [id, validatedInput.type, validatedInput.name, validatedInput.content, tokenCount, validatedInput.isActive ? 1 : 0]
-      );
-      
-      const created = await this.db.database.get<{
-        id: string;
-        type: string;
-        name: string;
-        content: string;
-        token_count: number;
-        is_active: number;
-        created_at: number;
-        updated_at: number;
-      }>('SELECT * FROM prompts WHERE id = ?', [id]);
-      
-      if (!created) {
-        throw new Error('Failed to create prompt');
-      }
-
-      // Broadcast update to notify all renderer processes
-      const updateChannel = created.type === 'system' ? '/prompts/system:update' : '/prompts/role:update';
-      this.broadcastUpdate(updateChannel);
-
-      return {
-        id: created.id,
-        type: created.type as 'system' | 'role',
-        name: created.name,
-        content: created.content,
-        tokenCount: created.token_count,
-        isActive: created.is_active === 1,
-        createdAt: created.created_at,
-        updatedAt: created.updated_at
-      };
-    });
-
-    this.ipc.setHandler('/prompt/update', async (input: unknown) => {
-      const validatedInput = input as PromptUpdateInput & { type?: 'system' | 'role' };
-      // If tokenCount wasn't provided but content changed, recompute it
-      const effectiveTokenCount =
-        validatedInput.tokenCount ?? countTokens(validatedInput.content);
-
-      await this.db.database.run(
-        `UPDATE prompts
-         SET name = ?, content = ?, token_count = ?, is_active = ?
-         WHERE id = ?`,
-        [validatedInput.name, validatedInput.content, effectiveTokenCount, validatedInput.isActive ? 1 : 0, validatedInput.id]
-      );
-
-      // Broadcast update to notify all renderer processes
-      let promptType = validatedInput.type;
-      if (!promptType) {
-        const row = await this.db.database.get<{ type: string }>(
-          'SELECT type FROM prompts WHERE id = ?',
-          [validatedInput.id]
-        );
-        promptType = (row?.type as 'system' | 'role') ?? 'role';
-      }
-      const updateChannel = promptType === 'system' ? '/prompts/system:update' : '/prompts/role:update';
-      this.broadcastUpdate(updateChannel);
-
-      return true;
-    });
-
-    this.ipc.setHandler('/prompt/delete', async (input: unknown) => {
-      const validatedInput = input as PromptDeleteInput;
-
-      // Get the prompt type before deleting for broadcast
-      const prompt = await this.db.database.get<{ type: string }>('SELECT type FROM prompts WHERE id = ?', [validatedInput.id]);
-
-      await this.db.database.run('DELETE FROM prompts WHERE id = ?', [validatedInput.id]);
-
-      // Broadcast update to notify all renderer processes
-      if (prompt) {
-        const updateChannel = prompt.type === 'system' ? '/prompts/system:update' : '/prompts/role:update';
-        this.broadcastUpdate(updateChannel);
-      }
-
-      return true;
-    });
-
-    // Migration handlers (currently disabled - migration modules not present)
-    // These handlers are kept for future implementation when migration is needed
-  }
-
-  async close() {
-    this.ipc.unregisterAll();
-    await this.db.close();
-  }
-
-  // Getter for database (for direct access if needed)
-  get database(): SecureDatabase {
-    return this.db;
-  }
-
-  // Helper method to broadcast updates to all renderer processes
-  private broadcastUpdate(channel: string, data?: unknown) {
-    const windows = BrowserWindow.getAllWindows();
-    for (const window of windows) {
-      window.webContents.send(channel, data);
-    }
-  }
-}
\ No newline at end of file
diff --git a/src/main/db/index.ts b/src/main/db/index.ts
index ba673e3..f8743b2 100644
--- a/src/main/db/index.ts
+++ b/src/main/db/index.ts
@@ -1,8 +1,10 @@
+// Export database components
 export { AsyncDatabase, PreparedStatement } from './async-database';
-export { SecureDatabase } from './secure-database';
 export { ConnectionPool } from './connection-pool';
 export { PooledDatabase } from './pooled-database';
 export { PooledDatabaseBridge } from './pooled-database-bridge';
+
+// Export types
 export type { RunResult } from './async-database';
 export type { PoolStats, SqlParameters, QueryResult } from './connection-pool';
 export type { PooledDatabaseConfig, PerformanceMetrics } from './pooled-database';
diff --git a/src/main/db/migrations/002_add_performance_indexes.sql b/src/main/db/migrations/002_add_performance_indexes.sql
deleted file mode 100644
index 0e92b3d..0000000
--- a/src/main/db/migrations/002_add_performance_indexes.sql
+++ /dev/null
@@ -1,20 +0,0 @@
--- Migration 002: Add composite indexes for performance optimization
--- Date: 2025-01-03
--- Purpose: Addresses performance issues identified in audit report
-
--- Update schema version
-UPDATE schema_version SET version = 2;
-
--- Composite indexes for common query patterns
-CREATE INDEX IF NOT EXISTS idx_files_path_workspace ON files(path, workspace_id);
-CREATE INDEX IF NOT EXISTS idx_prompts_type_active ON prompts(type, is_active);
-CREATE INDEX IF NOT EXISTS idx_preferences_key_updated ON preferences(key, updated_at);
-CREATE INDEX IF NOT EXISTS idx_file_contents_hash_created ON file_contents(hash, created_at);
-
--- Additional performance indexes
-CREATE INDEX IF NOT EXISTS idx_files_binary_workspace ON files(is_binary, workspace_id);
-CREATE INDEX IF NOT EXISTS idx_files_size_workspace ON files(size, workspace_id);
-CREATE INDEX IF NOT EXISTS idx_prompts_active_updated ON prompts(is_active, updated_at DESC);
-
--- Covering index for file content lookups
-CREATE INDEX IF NOT EXISTS idx_files_content_lookup ON files(workspace_id, path, content_hash, token_count);
\ No newline at end of file
diff --git a/src/main/db/pooled-database-bridge.ts b/src/main/db/pooled-database-bridge.ts
index 2913c7b..31c2c7b 100644
--- a/src/main/db/pooled-database-bridge.ts
+++ b/src/main/db/pooled-database-bridge.ts
@@ -4,11 +4,71 @@ import * as fs from 'node:fs/promises';
 
 import { app } from 'electron';
 
-import { WorkspaceState } from '../../types/file-types';
-
 import { PooledDatabase, PooledDatabaseConfig } from './pooled-database';
 import { QueryResult } from './connection-pool';
 
+// Define precise types locally to avoid React dependencies
+interface FileData {
+  path: string;
+  name: string;
+  size: number;
+  isDirectory: boolean;
+  isSymlink?: boolean;
+  isBinary?: boolean;
+  extension?: string;
+  content?: string;
+  tokenCount?: number;
+}
+
+interface SelectedFileReference {
+  path: string;
+  lines?: { start: number; end: number }[];
+}
+
+interface SystemPrompt {
+  id: string;
+  name: string;
+  content: string;
+  isSelected: boolean;
+}
+
+interface RolePrompt {
+  id: string;
+  name: string;
+  content: string;
+  isSelected: boolean;
+}
+
+interface Instruction {
+  id: string;
+  title: string;
+  content: string;
+  isGlobal: boolean;
+  isSelected?: boolean;
+}
+
+type FileTreeMode = 'none' | 'selected' | 'selected_with_roots' | 'complete';
+
+interface WorkspaceState {
+  selectedFolder: string | null;
+  allFiles: FileData[];
+  selectedFiles: SelectedFileReference[];
+  expandedNodes: Record<string, boolean>;
+  sortOrder: string;
+  searchTerm: string;
+  fileTreeMode: FileTreeMode;
+  exclusionPatterns: string[];
+  userInstructions: string;
+  tokenCounts: Record<string, number>;
+  folderIndex?: Map<string, string[]>;
+  customPrompts: {
+    systemPrompts: SystemPrompt[];
+    rolePrompts: RolePrompt[];
+  };
+  selectedInstructions?: Instruction[];
+  savedAt?: number;
+}
+
 // Error messages
 const DATABASE_NOT_INITIALIZED_ERROR = 'Database is not initialized';
 
diff --git a/src/main/db/retry-utils.js b/src/main/db/retry-utils.js
deleted file mode 100644
index e9609b4..0000000
--- a/src/main/db/retry-utils.js
+++ /dev/null
@@ -1,384 +0,0 @@
-const { EventEmitter } = require('events');
-
-const DatabaseErrorType = {
-  CONNECTION_FAILED: 'CONNECTION_FAILED',
-  TRANSACTION_DEADLOCK: 'TRANSACTION_DEADLOCK',
-  DATABASE_LOCKED: 'DATABASE_LOCKED',
-  DISK_FULL: 'DISK_FULL',
-  CORRUPT_DATABASE: 'CORRUPT_DATABASE',
-  WORKER_TIMEOUT: 'WORKER_TIMEOUT',
-  WORKER_TERMINATED: 'WORKER_TERMINATED',
-  UNKNOWN: 'UNKNOWN'
-};
-
-class DatabaseRetryUtility extends EventEmitter {
-  constructor() {
-    super();
-    this.retryStats = new Map();
-  }
-
-  static getInstance() {
-    if (!DatabaseRetryUtility.instance) {
-      DatabaseRetryUtility.instance = new DatabaseRetryUtility();
-    }
-    return DatabaseRetryUtility.instance;
-  }
-
-  /**
-   * Executes an operation with comprehensive retry logic
-   */
-  async executeWithRetry(operation, options = {}) {
-    const config = {
-      maxRetries: 3,
-      baseDelay: 100,
-      maxDelay: 5000,
-      exponentialBase: 2,
-      jitterFactor: 0.1,
-      retryableErrors: [
-        'SQLITE_BUSY',
-        'SQLITE_LOCKED',
-        'SQLITE_CANTOPEN',
-        'SQLITE_PROTOCOL',
-        'EBUSY',
-        'EAGAIN',
-        'Database operation timed out',
-        'Worker terminated',
-        'Connection failed'
-      ],
-      operation: 'database_operation',
-      ...options
-    };
-
-    const attempts = [];
-    const startTime = Date.now();
-    let lastError;
-
-    // Update stats
-    this.updateStats(config.operation, 'attempt');
-
-    for (let attempt = 0; attempt <= config.maxRetries; attempt++) {
-      const attemptStart = Date.now();
-      
-      try {
-        const result = await operation();
-        
-        // Record successful attempt
-        attempts.push({
-          attempt: attempt + 1,
-          delay: 0,
-          timestamp: attemptStart
-        });
-
-        this.updateStats(config.operation, 'success');
-        this.emit('retry:success', {
-          operation: config.operation,
-          attempt: attempt + 1,
-          totalTime: Date.now() - startTime
-        });
-
-        return {
-          success: true,
-          result,
-          attempts,
-          totalTime: Date.now() - startTime
-        };
-
-      } catch (error) {
-        lastError = error;
-        const errorType = this.classifyError(lastError);
-        
-        // Record failed attempt
-        attempts.push({
-          attempt: attempt + 1,
-          delay: 0,
-          error: lastError,
-          timestamp: attemptStart
-        });
-
-        this.emit('retry:attempt', {
-          operation: config.operation,
-          attempt: attempt + 1,
-          error: lastError,
-          errorType
-        });
-
-        // Check if error is retryable
-        if (!this.isRetryableError(lastError, config.retryableErrors)) {
-          this.updateStats(config.operation, 'failure');
-          this.emit('retry:failed', {
-            operation: config.operation,
-            error: lastError,
-            reason: 'non_retryable_error',
-            attempts
-          });
-
-          return {
-            success: false,
-            error: lastError,
-            attempts,
-            totalTime: Date.now() - startTime
-          };
-        }
-
-        // Don't retry on the last attempt
-        if (attempt >= config.maxRetries) {
-          break;
-        }
-
-        // Calculate delay for next attempt
-        const delay = this.calculateDelay(attempt, config);
-        attempts[attempts.length - 1].delay = delay;
-
-        this.emit('retry:delay', {
-          operation: config.operation,
-          attempt: attempt + 1,
-          delay,
-          nextAttempt: attempt + 2
-        });
-
-        // Wait before retrying
-        await this.sleep(delay);
-      }
-    }
-
-    // All retries exhausted
-    this.updateStats(config.operation, 'failure');
-    this.emit('retry:exhausted', {
-      operation: config.operation,
-      finalError: lastError,
-      totalAttempts: config.maxRetries + 1,
-      totalTime: Date.now() - startTime
-    });
-
-    return {
-      success: false,
-      error: lastError,
-      attempts,
-      totalTime: Date.now() - startTime
-    };
-  }
-
-  /**
-   * Specialized retry for database connections with exponential backoff
-   */
-  async retryConnection(connectionFn, maxRetries = 5) {
-    const result = await this.executeWithRetry(connectionFn, {
-      maxRetries,
-      baseDelay: 500,
-      maxDelay: 10_000,
-      exponentialBase: 2.5,
-      jitterFactor: 0.2,
-      operation: 'database_connection',
-      retryableErrors: [
-        'SQLITE_BUSY',
-        'SQLITE_LOCKED',
-        'SQLITE_CANTOPEN',
-        'ENOENT',
-        'EACCES',
-        'Connection failed'
-      ]
-    });
-
-    if (!result.success) {
-      throw new Error(`Connection failed after ${maxRetries + 1} attempts: ${result.error?.message}`);
-    }
-
-    return result.result;
-  }
-
-  /**
-   * Specialized retry for transactions with deadlock handling
-   */
-  async retryTransaction(transactionFn, maxRetries = 3) {
-    const result = await this.executeWithRetry(transactionFn, {
-      maxRetries,
-      baseDelay: 50,
-      maxDelay: 1000,
-      exponentialBase: 1.5,
-      jitterFactor: 0.3,
-      operation: 'database_transaction',
-      retryableErrors: [
-        'SQLITE_BUSY',
-        'SQLITE_LOCKED',
-        'database is locked',
-        'deadlock'
-      ]
-    });
-
-    if (!result.success) {
-      throw new Error(`Transaction failed after ${maxRetries + 1} attempts: ${result.error?.message}`);
-    }
-
-    return result.result;
-  }
-
-  /**
-   * Specialized retry for worker operations
-   */
-  async retryWorkerOperation(workerFn, maxRetries = 3) {
-    const result = await this.executeWithRetry(workerFn, {
-      maxRetries,
-      baseDelay: 200,
-      maxDelay: 2000,
-      exponentialBase: 2,
-      jitterFactor: 0.1,
-      operation: 'worker_operation',
-      retryableErrors: [
-        'Database operation timed out',
-        'Worker terminated',
-        'Worker error',
-        'ECONNRESET'
-      ]
-    });
-
-    if (!result.success) {
-      throw new Error(`Worker operation failed after ${maxRetries + 1} attempts: ${result.error?.message}`);
-    }
-
-    return result.result;
-  }
-
-  /**
-   * Classify database errors for better handling
-   */
-  classifyError(error) {
-    const message = error.message.toLowerCase();
-    
-    if (message.includes('sqlite_busy') || message.includes('database is locked')) {
-      return DatabaseErrorType.DATABASE_LOCKED;
-    }
-    if (message.includes('deadlock')) {
-      return DatabaseErrorType.TRANSACTION_DEADLOCK;
-    }
-    if (message.includes('connection') || message.includes('cantopen')) {
-      return DatabaseErrorType.CONNECTION_FAILED;
-    }
-    if (message.includes('disk') || message.includes('no space')) {
-      return DatabaseErrorType.DISK_FULL;
-    }
-    if (message.includes('corrupt') || message.includes('malformed')) {
-      return DatabaseErrorType.CORRUPT_DATABASE;
-    }
-    if (message.includes('timeout')) {
-      return DatabaseErrorType.WORKER_TIMEOUT;
-    }
-    if (message.includes('worker terminated')) {
-      return DatabaseErrorType.WORKER_TERMINATED;
-    }
-    
-    return DatabaseErrorType.UNKNOWN;
-  }
-
-  /**
-   * Check if an error is retryable based on configuration
-   */
-  isRetryableError(error, retryableErrors) {
-    const errorMessage = error.message.toLowerCase();
-    const errorCode = this.getErrorCode(error);
-    
-    return retryableErrors.some(retryableError => {
-      const pattern = retryableError.toLowerCase();
-      return errorMessage.includes(pattern) || 
-             (errorCode && errorCode.toString().toLowerCase().includes(pattern));
-    });
-  }
-
-  /**
-   * Safely extract error code from error object
-   */
-  getErrorCode(error) {
-    if ('code' in error) {
-      return error.code;
-    }
-    return undefined;
-  }
-
-  /**
-   * Calculate delay with exponential backoff and jitter
-   * Uses exponential backoff formula: baseDelay * (exponentialBase ^ attemptNumber)
-   * This provides progressively longer delays between retries to avoid overwhelming the system
-   */
-  calculateDelay(attempt, options) {
-    // Exponential backoff: delay increases exponentially with each attempt
-    const exponentialDelay = options.baseDelay * Math.pow(options.exponentialBase, attempt);
-    const cappedDelay = Math.min(exponentialDelay, options.maxDelay);
-    
-    // Add jitter to prevent thundering herd
-    const jitter = cappedDelay * options.jitterFactor * (Math.random() - 0.5);
-    const finalDelay = Math.max(0, cappedDelay + jitter);
-    
-    return Math.round(finalDelay);
-  }
-
-  /**
-   * Sleep for specified milliseconds
-   */
-  sleep(ms) {
-    return new Promise(resolve => setTimeout(resolve, ms));
-  }
-
-  /**
-   * Update retry statistics
-   */
-  updateStats(operation, type) {
-    if (!this.retryStats.has(operation)) {
-      this.retryStats.set(operation, {
-        totalAttempts: 0,
-        successCount: 0,
-        failureCount: 0
-      });
-    }
-
-    const stats = this.retryStats.get(operation);
-    
-    switch (type) {
-      case 'attempt':
-        stats.totalAttempts++;
-        break;
-      case 'success':
-        stats.successCount++;
-        break;
-      case 'failure':
-        stats.failureCount++;
-        stats.lastFailure = new Date();
-        break;
-    }
-  }
-
-  /**
-   * Get retry statistics for monitoring
-   */
-  getRetryStats() {
-    const result = new Map();
-    
-    for (const [operation, stats] of this.retryStats) {
-      result.set(operation, {
-        ...stats,
-        successRate: stats.totalAttempts > 0 ? stats.successCount / stats.totalAttempts : 0
-      });
-    }
-    
-    return result;
-  }
-
-  /**
-   * Clear retry statistics
-   */
-  clearStats() {
-    this.retryStats.clear();
-  }
-}
-
-// Singleton instance
-const retryUtility = DatabaseRetryUtility.getInstance();
-
-// Export convenience functions
-module.exports = {
-  DatabaseRetryUtility,
-  DatabaseErrorType,
-  retryUtility,
-  executeWithRetry: retryUtility.executeWithRetry.bind(retryUtility),
-  retryConnection: retryUtility.retryConnection.bind(retryUtility),
-  retryTransaction: retryUtility.retryTransaction.bind(retryUtility),
-  retryWorkerOperation: retryUtility.retryWorkerOperation.bind(retryUtility)
-};
\ No newline at end of file
diff --git a/src/main/db/schema.sql b/src/main/db/schema.sql
deleted file mode 100644
index 169a0e4..0000000
--- a/src/main/db/schema.sql
+++ /dev/null
@@ -1,108 +0,0 @@
--- Enable foreign key constraints
-PRAGMA foreign_keys = ON;
-
--- Version tracking for future migrations
-CREATE TABLE schema_version (
-  version INTEGER PRIMARY KEY,
-  applied_at INTEGER DEFAULT (strftime('%s', 'now'))
-);
-
--- Workspaces with complete state serialization
-CREATE TABLE workspaces (
-  id TEXT PRIMARY KEY,
-  name TEXT NOT NULL UNIQUE,
-  folder_path TEXT NOT NULL,
-  state_json TEXT NOT NULL, -- Complete serialized WorkspaceState
-  created_at INTEGER DEFAULT (strftime('%s', 'now')),
-  updated_at INTEGER DEFAULT (strftime('%s', 'now')),
-  last_accessed INTEGER DEFAULT (strftime('%s', 'now'))
-);
-
--- File metadata with content deduplication
-CREATE TABLE files (
-  id INTEGER PRIMARY KEY AUTOINCREMENT,
-  path TEXT NOT NULL,
-  workspace_id TEXT NOT NULL,
-  content_hash TEXT,
-  size INTEGER NOT NULL,
-  is_binary BOOLEAN NOT NULL DEFAULT 0,
-  token_count INTEGER,
-  last_modified INTEGER,
-  FOREIGN KEY (workspace_id) REFERENCES workspaces(id) ON DELETE CASCADE,
-  UNIQUE(path, workspace_id)
-);
-
--- Deduplicated file contents with compression
-CREATE TABLE file_contents (
-  hash TEXT PRIMARY KEY,
-  content BLOB NOT NULL, -- Compressed with zlib
-  original_size INTEGER NOT NULL,
-  compressed_size INTEGER NOT NULL,
-  compression_ratio REAL,
-  created_at INTEGER DEFAULT (strftime('%s', 'now'))
-);
-
--- User preferences (replaces electron-settings)
-CREATE TABLE preferences (
-  key TEXT PRIMARY KEY,
-  value TEXT NOT NULL,
-  encrypted BOOLEAN DEFAULT 0,
-  updated_at INTEGER DEFAULT (strftime('%s', 'now'))
-);
-
--- System and role prompts
-CREATE TABLE prompts (
-  id TEXT PRIMARY KEY,
-  type TEXT NOT NULL CHECK(type IN ('system', 'role')),
-  name TEXT NOT NULL,
-  content TEXT NOT NULL,
-  token_count INTEGER,
-  is_active BOOLEAN DEFAULT 1,
-  created_at INTEGER DEFAULT (strftime('%s', 'now')),
-  updated_at INTEGER DEFAULT (strftime('%s', 'now'))
-);
-
--- Instructions and documentation
-CREATE TABLE instructions (
-  id TEXT PRIMARY KEY,
-  name TEXT NOT NULL UNIQUE,
-  content TEXT NOT NULL,
-  category TEXT,
-  created_at INTEGER DEFAULT (strftime('%s', 'now')),
-  updated_at INTEGER DEFAULT (strftime('%s', 'now'))
-);
-
--- Audit log for critical operations
-CREATE TABLE audit_log (
-  id INTEGER PRIMARY KEY AUTOINCREMENT,
-  operation TEXT NOT NULL,
-  table_name TEXT,
-  record_id TEXT,
-  old_value TEXT,
-  new_value TEXT,
-  timestamp INTEGER DEFAULT (strftime('%s', 'now'))
-);
-
--- Performance indexes
-CREATE INDEX idx_files_workspace ON files(workspace_id);
-CREATE INDEX idx_files_hash ON files(content_hash);
-CREATE INDEX idx_workspaces_accessed ON workspaces(last_accessed DESC);
-CREATE INDEX idx_audit_timestamp ON audit_log(timestamp DESC);
-
--- Auto-update triggers
-CREATE TRIGGER update_workspace_timestamp 
-AFTER UPDATE ON workspaces
-BEGIN
-  UPDATE workspaces SET updated_at = strftime('%s', 'now') 
-  WHERE id = NEW.id;
-END;
-
-CREATE TRIGGER update_prompt_timestamp 
-AFTER UPDATE ON prompts
-BEGIN
-  UPDATE prompts SET updated_at = strftime('%s', 'now') 
-  WHERE id = NEW.id;
-END;
-
--- Insert initial schema version
-INSERT INTO schema_version (version) VALUES (1);
\ No newline at end of file
diff --git a/src/main/db/secure-database.ts b/src/main/db/secure-database.ts
deleted file mode 100644
index 3acef42..0000000
--- a/src/main/db/secure-database.ts
+++ /dev/null
@@ -1,443 +0,0 @@
-import * as crypto from 'node:crypto';
-import * as os from 'node:os';
-import * as fs from 'node:fs/promises';
-import * as path from 'node:path';
-
-import { machineIdSync } from 'node-machine-id';
-import * as keytar from 'keytar';
-
-import { AsyncDatabase } from './async-database';
-
-export class SecureDatabase {
-  private db!: AsyncDatabase;
-  private encryptionKey!: string;
-
-  static async create(dbPath: string): Promise<SecureDatabase> {
-    const instance = new SecureDatabase();
-    await instance.initialize(dbPath);
-    return instance;
-  }
-
-  private async initialize(dbPath: string) {
-    // Derive encryption key
-    this.encryptionKey = await this.deriveEncryptionKey();
-    
-    // Create encrypted database
-    this.db = new AsyncDatabase(dbPath, {
-      encryptionKey: this.encryptionKey
-    });
-    
-    // Initialize schema if needed
-    await this.initializeSchema();
-  }
-
-  private async deriveEncryptionKey(): Promise<string> {
-    const SERVICE_NAME = 'com.pasteflow.app';
-    const ACCOUNT_NAME = 'db-encryption-key';
-    
-    // Try to get existing key from macOS Keychain
-    let baseSecret = await keytar.getPassword(SERVICE_NAME, ACCOUNT_NAME);
-    
-    if (!baseSecret) {
-      // Generate new key on first run
-      const newKey = crypto.randomBytes(32);
-      baseSecret = newKey.toString('base64');
-      
-      // Store in Keychain
-      await keytar.setPassword(SERVICE_NAME, ACCOUNT_NAME, baseSecret);
-      
-      console.log('Generated new database encryption key');
-    }
-    
-    // Derive key with device-specific salt
-    const deviceSalt = this.getDeviceSalt();
-    const derivedKey = crypto.pbkdf2Sync(
-      baseSecret,
-      deviceSalt,
-      100_000,  // iterations
-      32,      // key length
-      'sha256'
-    );
-    
-    return derivedKey.toString('hex');
-  }
-
-  private getDeviceSalt(): Buffer {
-    // Combine multiple device-specific identifiers
-    const deviceId = machineIdSync();
-    const username = os.userInfo().username;
-    const hostname = os.hostname();
-    
-    return crypto.createHash('sha256')
-      .update(deviceId)
-      .update(username)
-      .update(hostname)
-      .update('pasteflow-v2-salt')
-      .digest();
-  }
-
-  private async initializeSchema() {
-    // Check if schema exists
-    const versionRow = await this.db.get<{ version: number }>(
-      'SELECT version FROM schema_version ORDER BY version DESC LIMIT 1'
-    ).catch(() => null);
-    
-    if (!versionRow) {
-      // Load and execute schema
-      const schemaSQL = await fs.readFile(
-        // eslint-disable-next-line unicorn/prefer-module
-        path.join(__dirname, 'schema.sql'),
-        'utf8'
-      );
-      
-      await this.db.exec(schemaSQL);
-      console.log('Database schema initialized');
-    }
-    
-    // Apply any pending migrations
-    await this.applyMigrations();
-  }
-  
-  private async applyMigrations() {
-    // Get current schema version
-    const versionRow = await this.db.get<{ version: number }>(
-      'SELECT version FROM schema_version ORDER BY version DESC LIMIT 1'
-    );
-    
-    const currentVersion = versionRow?.version || 1;
-    
-    // Check for migration files
-    // eslint-disable-next-line unicorn/prefer-module
-    const migrationsDir = path.join(__dirname, 'migrations');
-    
-    try {
-      const files = await fs.readdir(migrationsDir).catch(() => []);
-      const migrationFiles = files
-        .filter(f => f.endsWith('.sql'))
-        .sort(); // Ensure migrations run in order
-      
-      for (const file of migrationFiles) {
-        // Extract version from filename (e.g., "002_add_performance_indexes.sql" -> 2)
-        const versionMatch = file.match(/^(\d+)_/);
-        if (!versionMatch) continue;
-        
-        const migrationVersion = Number.parseInt(versionMatch[1], 10);
-        
-        // Skip if already applied
-        if (migrationVersion <= currentVersion) continue;
-        
-        // Apply migration
-        console.log(`Applying migration ${file}...`);
-        const migrationSQL = await fs.readFile(
-          path.join(migrationsDir, file),
-          'utf8'
-        );
-        
-        await this.db.exec(migrationSQL);
-        console.log(`Migration ${file} applied successfully`);
-      }
-    } catch (error) {
-      // Migrations directory doesn't exist yet - that's okay
-      if (error instanceof Error && 'code' in error && (error as NodeJS.ErrnoException).code !== 'ENOENT') {
-        console.error('Error applying migrations:', error);
-      }
-    }
-  }
-
-  // Delegate database operations
-  get database(): AsyncDatabase {
-    return this.db;
-  }
-
-  // Workspace operations
-  async createWorkspace(name: string, folderPath: string, state: Record<string, unknown>): Promise<string> {
-    const id = crypto.randomUUID();
-    await this.db.run(
-      'INSERT INTO workspaces (id, name, folder_path, state_json) VALUES (?, ?, ?, ?)',
-      [id, name, folderPath, JSON.stringify(state)]
-    );
-    return id;
-  }
-
-  async getWorkspace(id: string): Promise<WorkspaceRecord | undefined> {
-    const row = await this.db.get<WorkspaceRow>(
-      'SELECT * FROM workspaces WHERE id = ?',
-      [id]
-    );
-    
-    if (!row) return undefined;
-    
-    return {
-      id: row.id,
-      name: row.name,
-      folderPath: row.folder_path,
-      state: JSON.parse(row.state_json) as Record<string, unknown>,
-      createdAt: row.created_at,
-      updatedAt: row.updated_at,
-      lastAccessed: row.last_accessed
-    };
-  }
-
-  async updateWorkspace(id: string, state: Record<string, unknown>): Promise<void> {
-    await this.db.run(
-      'UPDATE workspaces SET state_json = ?, last_accessed = strftime("%s", "now") WHERE id = ?',
-      [JSON.stringify(state), id]
-    );
-  }
-
-  async deleteWorkspace(id: string): Promise<void> {
-    await this.db.run('DELETE FROM workspaces WHERE id = ?', [id]);
-  }
-
-  async listWorkspaces(): Promise<WorkspaceRecord[]> {
-    const rows = await this.db.all<WorkspaceRow>(
-      'SELECT * FROM workspaces ORDER BY last_accessed DESC'
-    );
-    
-    return rows.map(row => ({
-      id: row.id,
-      name: row.name,
-      folderPath: row.folder_path,
-      state: JSON.parse(row.state_json) as Record<string, unknown>,
-      createdAt: row.created_at,
-      updatedAt: row.updated_at,
-      lastAccessed: row.last_accessed
-    }));
-  }
-
-  // File operations
-  async saveFileContent(workspaceId: string, filePath: string, content: string, tokenCount?: number): Promise<void> {
-    const hash = crypto.createHash('sha256').update(content).digest('hex');
-    
-    // Save content if new
-    const existing = await this.db.get(
-      'SELECT hash FROM file_contents WHERE hash = ?',
-      [hash]
-    );
-    
-    if (!existing) {
-      const compressed = await this.compressContent(content);
-      await this.db.run(
-        'INSERT INTO file_contents (hash, content, original_size, compressed_size, compression_ratio) VALUES (?, ?, ?, ?, ?)',
-        [hash, compressed, content.length, compressed.length, compressed.length / content.length]
-      );
-    }
-    
-    // Update file metadata
-    await this.db.run(
-      `INSERT OR REPLACE INTO files (path, workspace_id, content_hash, size, is_binary, token_count, last_modified)
-       VALUES (?, ?, ?, ?, ?, ?, strftime("%s", "now"))`,
-      [filePath, workspaceId, hash, content.length, 0, tokenCount || null]
-    );
-  }
-
-  async getFileContent(workspaceId: string, filePath: string): Promise<string | null> {
-    const file = await this.db.get<{ content_hash: string }>(
-      'SELECT content_hash FROM files WHERE workspace_id = ? AND path = ?',
-      [workspaceId, filePath]
-    );
-    
-    if (!file) return null;
-    
-    const content = await this.db.get<{ content: Buffer }>(
-      'SELECT content FROM file_contents WHERE hash = ?',
-      [file.content_hash]
-    );
-    
-    if (!content) return null;
-    
-    return this.decompressContent(content.content);
-  }
-
-  // Batch query method to eliminate N+1 patterns
-  async getFilesContentBatch(workspaceId: string, filePaths: string[]): Promise<Map<string, string | null>> {
-    if (filePaths.length === 0) {
-      return new Map();
-    }
-
-    // Create placeholders for the IN clause
-    const placeholders = filePaths.map(() => '?').join(',');
-    
-    // Fetch all file records in one query
-    const files = await this.db.all<{ path: string; content_hash: string }>(
-      `SELECT path, content_hash 
-       FROM files 
-       WHERE workspace_id = ? AND path IN (${placeholders})`,
-      [workspaceId, ...filePaths]
-    );
-    
-    // Create a map of path to content hash
-    const pathToHash = new Map<string, string>();
-    const uniqueHashes = new Set<string>();
-    
-    for (const file of files) {
-      if (file.content_hash) {
-        pathToHash.set(file.path, file.content_hash);
-        uniqueHashes.add(file.content_hash);
-      }
-    }
-    
-    // Fetch all unique content hashes in one query
-    const hashArray = [...uniqueHashes];
-    const contentMap = new Map<string, string>();
-    
-    if (hashArray.length > 0) {
-      const contentPlaceholders = hashArray.map(() => '?').join(',');
-      const contents = await this.db.all<{ hash: string; content: Buffer }>(
-        `SELECT hash, content 
-         FROM file_contents 
-         WHERE hash IN (${contentPlaceholders})`,
-        hashArray
-      );
-      
-      // Decompress and store content
-      for (const content of contents) {
-        try {
-          const decompressed = await this.decompressContent(content.content);
-          contentMap.set(content.hash, decompressed);
-        } catch (error) {
-          console.error(`Error decompressing content for hash ${content.hash}:`, error);
-          // Mark this content as corrupted/unavailable
-          contentMap.set(content.hash, '');
-        }
-      }
-    }
-    
-    // Build the result map
-    const result = new Map<string, string | null>();
-    for (const path of filePaths) {
-      const hash = pathToHash.get(path);
-      if (hash && contentMap.has(hash)) {
-        result.set(path, contentMap.get(hash)!);
-      } else {
-        result.set(path, null);
-      }
-    }
-    
-    return result;
-  }
-
-  // Preference operations
-  async getPreference(key: string): Promise<unknown> {
-    const row = await this.db.get<{ value: string; encrypted: number }>(
-      'SELECT value, encrypted FROM preferences WHERE key = ?',
-      [key]
-    );
-    
-    if (!row) return undefined;
-    
-    const value = row.encrypted ? await this.decrypt(row.value) : row.value;
-    return JSON.parse(value);
-  }
-
-  async setPreference(key: string, value: unknown, encrypted = false): Promise<void> {
-    const jsonValue = JSON.stringify(value);
-    const storedValue = encrypted ? await this.encrypt(jsonValue) : jsonValue;
-    
-    await this.db.run(
-      'INSERT OR REPLACE INTO preferences (key, value, encrypted) VALUES (?, ?, ?)',
-      [key, storedValue, encrypted ? 1 : 0]
-    );
-  }
-
-  // Compression helpers
-  private async compressContent(content: string): Promise<Buffer> {
-    const { promisify } = await import('node:util');
-    const zlib = await import('node:zlib');
-    const deflate = promisify(zlib.deflate);
-    return deflate(Buffer.from(content, 'utf8'));
-  }
-
-  private async decompressContent(compressed: Buffer): Promise<string> {
-    const { promisify } = await import('node:util');
-    const zlib = await import('node:zlib');
-    const inflate = promisify(zlib.inflate);
-    const decompressed = await inflate(compressed);
-    return decompressed.toString('utf8');
-  }
-
-  // Additional helpers for state handlers
-  async saveFileContentByHash(content: string, _filePath: string): Promise<string> {
-    const hash = crypto.createHash('sha256').update(content).digest('hex');
-    
-    // Save content if new
-    const existing = await this.db.get(
-      'SELECT hash FROM file_contents WHERE hash = ?',
-      [hash]
-    );
-    
-    if (!existing) {
-      const compressed = await this.compressContent(content);
-      await this.db.run(
-        'INSERT INTO file_contents (hash, content, original_size, compressed_size, compression_ratio) VALUES (?, ?, ?, ?, ?)',
-        [hash, compressed, content.length, compressed.length, compressed.length / content.length]
-      );
-    }
-    
-    return hash;
-  }
-
-  async getContentByHash(hash: string): Promise<string> {
-    const content = await this.db.get<{ content: Buffer }>(
-      'SELECT content FROM file_contents WHERE hash = ?',
-      [hash]
-    );
-    
-    if (!content) {
-      throw new Error(`Content not found for hash: ${hash}`);
-    }
-    
-    return this.decompressContent(content.content);
-  }
-
-  async encryptValue(value: string): Promise<string> {
-    return this.encrypt(value);
-  }
-
-  async decryptValue(value: string): Promise<string> {
-    return this.decrypt(value);
-  }
-
-  // Encryption helpers
-  private async encrypt(text: string): Promise<string> {
-    const iv = crypto.randomBytes(16);
-    const cipher = crypto.createCipheriv('aes-256-cbc', Buffer.from(this.encryptionKey, 'hex'), iv);
-    let encrypted = cipher.update(text, 'utf8', 'hex');
-    encrypted += cipher.final('hex');
-    return iv.toString('hex') + ':' + encrypted;
-  }
-
-  private async decrypt(text: string): Promise<string> {
-    const [ivHex, encrypted] = text.split(':');
-    const iv = Buffer.from(ivHex, 'hex');
-    const decipher = crypto.createDecipheriv('aes-256-cbc', Buffer.from(this.encryptionKey, 'hex'), iv);
-    let decrypted = decipher.update(encrypted, 'hex', 'utf8');
-    decrypted += decipher.final('utf8');
-    return decrypted;
-  }
-
-  async close(): Promise<void> {
-    await this.db.close();
-  }
-}
-
-// Type definitions
-interface WorkspaceRow {
-  id: string;
-  name: string;
-  folder_path: string;
-  state_json: string;
-  created_at: number;
-  updated_at: number;
-  last_accessed: number;
-}
-
-interface WorkspaceRecord {
-  id: string;
-  name: string;
-  folderPath: string;
-  state: Record<string, unknown>;
-  createdAt: number;
-  updatedAt: number;
-  lastAccessed: number;
-}
\ No newline at end of file
diff --git a/src/main/handlers/state-handlers.ts b/src/main/handlers/state-handlers.ts
deleted file mode 100644
index 7c735e7..0000000
--- a/src/main/handlers/state-handlers.ts
+++ /dev/null
@@ -1,854 +0,0 @@
-import { promises as fs } from 'node:fs';
-
-import { BrowserWindow } from 'electron';
-import { v4 as uuidv4 } from 'uuid';
-
-import { SecureDatabase } from '../db/secure-database';
-import { SecureIpcLayer } from '../ipc/secure-ipc';
-import { countTokens } from '../utils/token-utils';
-// Removed custom validation imports - using Zod validation from SecureIpcLayer instead
-
-interface ContentDeduplicator {
-  storeFileContent(content: string, filePath: string): Promise<string>;
-  retrieveContent(hash: string): Promise<string>;
-}
-
-export class StateHandlers {
-  private contentDeduplicator: ContentDeduplicator;
-  
-  private estimateTokenCount(text: string): number {
-    return countTokens(text);
-  }
-
-  private delay(ms: number) {
-    return new Promise((resolve) => setTimeout(resolve, ms));
-  }
-
-  private async findWorkspaceByIdOrName(idOrName: string) {
-    // Case-insensitive, trimmed name matching; id is exact
-    return await this.db.database.get(
-      // NOTE: LOWER(TRIM(?)) avoids casing/whitespace mismatches on names
-      'SELECT * FROM workspaces WHERE id = ? OR LOWER(name) = LOWER(TRIM(?)) LIMIT 1',
-      [idOrName, idOrName]
-    ) as {
-      id: string;
-      name: string;
-      folder_path: string;
-      state_json: string;
-      created_at: number;
-      updated_at: number;
-      last_accessed: number;
-    } | undefined;
-  }
-
-  constructor(
-    private db: SecureDatabase,
-    private ipc: SecureIpcLayer
-  ) {
-    this.contentDeduplicator = {
-      storeFileContent: async (content: string, filePath: string) => {
-        return await this.db.saveFileContentByHash(content, filePath);
-      },
-      retrieveContent: async (hash: string) => {
-        return await this.db.getContentByHash(hash);
-      }
-    };
-    this.registerHandlers();
-  }
-
-  private registerHandlers() {
-    // Workspace handlers
-    this.ipc.setHandler('/workspace/list', async () => {
-      try {
-        const workspaces = await this.db.database.all(
-          'SELECT id, name, folder_path as folderPath, state_json, created_at as createdAt, updated_at as updatedAt, last_accessed as lastAccessed FROM workspaces ORDER BY last_accessed DESC'
-        ) as {
-          id: string;
-          name: string;
-          folderPath: string;
-          state_json: string;
-          createdAt: number;
-          updatedAt: number;
-          lastAccessed: number;
-        }[];
-        
-        // Parse the state JSON for each workspace
-        return workspaces.map(ws => ({
-          id: ws.id,
-          name: ws.name,
-          folderPath: ws.folderPath,
-          state: JSON.parse(ws.state_json || '{}'),
-          createdAt: ws.createdAt,
-          updatedAt: ws.updatedAt,
-          lastAccessed: ws.lastAccessed
-        }));
-      } catch (error) {
-        throw new Error(`Failed to list workspaces: ${(error as Error).message}. Check database connection and table integrity.`);
-      }
-    });
-
-    // Input already validated by SecureIpcLayer (Zod). Use directly.
-    this.ipc.setHandler('/workspace/create', async (input: { name: string; folderPath: string; state?: unknown }) => {
-      try {
-        const id = uuidv4();
-        const now = Math.floor(Date.now() / 1000);
-
-        await this.db.database.run(
-          'INSERT INTO workspaces (id, name, folder_path, state_json, created_at, updated_at, last_accessed) VALUES (?, ?, ?, ?, ?, ?, ?)',
-          [id, input.name, input.folderPath, JSON.stringify(input.state || {}), now, now, now]
-        );
-
-        return {
-          id,
-          name: input.name,
-          folderPath: input.folderPath,
-          state: input.state || {},
-          createdAt: now,
-          updatedAt: now,
-          lastAccessed: now
-        };
-      } catch (error) {
-        const err = error as { code?: string; message?: string };
-        if (err.code === 'SQLITE_CONSTRAINT_UNIQUE') {
-          const name = input?.name ?? '<unknown>';
-          throw new Error(`Cannot create workspace '${name}': A workspace with this name already exists. Choose a different name.`);
-        }
-        const name = input?.name ?? '<unknown>';
-        const folderPath = input?.folderPath ?? '<unknown>';
-        throw new Error(`Failed to create workspace '${name}' at '${folderPath}': ${err.message || 'Unknown error'}. Verify folder path is valid and database is writable.`);
-      }
-    });
-
-    // Zod validated (input.id is non-empty string; transitional: may be name or UUID)
-    this.ipc.setHandler('/workspace/load', async (input: { id: string }) => {
-      try {
-        let workspace = await this.findWorkspaceByIdOrName(input.id);
-
-        if (!workspace) {
-          const isUuid = /^[\da-f]{8}-[\da-f]{4}-[1-5][\da-f]{3}-[89ab][\da-f]{3}-[\da-f]{12}$/i.test(input.id);
-          if (!isUuid) {
-            const maxAttempts = 3;
-            for (let attempt = 0; attempt < maxAttempts; attempt++) {
-              await this.delay(50 + attempt * 50);
-              workspace = await this.findWorkspaceByIdOrName(input.id);
-              if (workspace) break;
-            }
-          }
-        }
-
-        if (!workspace) {
-          return null;
-        }
-
-        return {
-          id: workspace.id,
-          name: workspace.name,
-          folderPath: workspace.folder_path,
-          state: JSON.parse(workspace.state_json),
-          createdAt: workspace.created_at,
-          updatedAt: workspace.updated_at,
-          lastAccessed: workspace.last_accessed
-        };
-      } catch (error) {
-        const errorMessage = (error as Error).message;
-        throw new Error(`Failed to load workspace '${input.id}': ${errorMessage}. Check database connection and workspace data integrity.`);
-      }
-    });
-
-    // Zod validated (input.id is UUID per schemas; input.state is a record)
-    this.ipc.setHandler('/workspace/update', async (input: { id: string; state: Record<string, unknown> }) => {
-      try {
-        const now = Math.floor(Date.now() / 1000);
-
-        const result = await this.db.database.run(
-          'UPDATE workspaces SET state_json = ?, updated_at = ? WHERE id = ?',
-          [JSON.stringify(input.state), now, input.id]
-        );
-
-        if (result.changes === 0) {
-          throw new Error(`Workspace '${input.id}' not found during update operation. Verify workspace exists before updating.`);
-        }
-
-        // Broadcast update to notify all renderer processes
-        this.broadcastUpdate('/workspace/current:update');
-
-        return true;
-      } catch (error) {
-        const errorMessage = (error as Error).message;
-        if (errorMessage.includes('not found')) {
-          throw error;
-        }
-        throw new Error(`Failed to update workspace '${input.id}': ${errorMessage}. Check workspace state format and database permissions.`);
-      }
-    });
-
-    // Zod validated (input.id is UUID per schemas)
-    this.ipc.setHandler('/workspace/delete', async (input: { id: string }) => {
-      try {
-        const result = await this.db.database.run('DELETE FROM workspaces WHERE id = ?', [input.id]);
-
-        if (result.changes === 0) {
-          throw new Error(`Workspace '${input.id}' not found during delete operation. Workspace may have already been deleted.`);
-        }
-
-        return true;
-      } catch (error) {
-        const errorMessage = (error as Error).message;
-        if (errorMessage.includes('not found')) {
-          throw error;
-        }
-        throw new Error(`Failed to delete workspace '${input.id}': ${errorMessage}. Check database permissions and workspace references.`);
-      }
-    });
-
-    this.ipc.setHandler('/workspace/current', async () => {
-      try {
-        // Get the most recently accessed workspace
-        const workspace = await this.db.database.get(
-          'SELECT * FROM workspaces ORDER BY last_accessed DESC LIMIT 1'
-        ) as {
-          id: string;
-          name: string;
-          folder_path: string;
-          state_json: string;
-          created_at: number;
-          updated_at: number;
-          last_accessed: number;
-        } | undefined;
-        
-        if (!workspace) {
-          return null;
-        }
-        
-        return {
-          id: workspace.id,
-          name: workspace.name,
-          folderPath: workspace.folder_path,
-          state: JSON.parse(workspace.state_json),
-          createdAt: workspace.created_at,
-          updatedAt: workspace.updated_at,
-          lastAccessed: workspace.last_accessed
-        };
-      } catch (error) {
-        throw new Error(`Failed to get current workspace: ${(error as Error).message}. Check database connection and workspace data integrity.`);
-      }
-    });
-
-    this.ipc.setHandler('/workspace/set-current', async (input: { workspace: any }) => {
-      let workspace: { id: string; name: string } | undefined;
-      try {
-        // Update the current workspace state
-        workspace = await this.db.database.get(
-          'SELECT id, name FROM workspaces ORDER BY last_accessed DESC LIMIT 1'
-        ) as { id: string; name: string } | undefined;
-        
-        if (workspace) {
-          const now = Math.floor(Date.now() / 1000);
-          await this.db.database.run(
-            'UPDATE workspaces SET state_json = ?, updated_at = ?, last_accessed = ? WHERE id = ?',
-            [JSON.stringify(input.workspace), now, now, workspace.id]
-          );
-        }
-        
-        return true;
-      } catch (error) {
-        const workspaceName = workspace?.name || 'current workspace';
-        throw new Error(`Failed to set current workspace '${workspaceName}': ${(error as Error).message}. Check workspace data format and database permissions.`);
-      }
-    });
-
-    this.ipc.setHandler('/workspace/clear', async () => {
-      let workspace: { id: string; name: string } | undefined;
-      try {
-        // Clear current workspace by setting state to empty
-        workspace = await this.db.database.get(
-          'SELECT id, name FROM workspaces ORDER BY last_accessed DESC LIMIT 1'
-        ) as { id: string; name: string } | undefined;
-        
-        if (workspace) {
-          const now = Math.floor(Date.now() / 1000);
-          await this.db.database.run(
-            'UPDATE workspaces SET state_json = ?, updated_at = ? WHERE id = ?',
-            [JSON.stringify({}), now, workspace.id]
-          );
-        }
-        
-        return true;
-      } catch (error) {
-        const workspaceName = workspace?.name || 'current workspace';
-        throw new Error(`Failed to clear workspace '${workspaceName}': ${(error as Error).message}. Check database permissions.`);
-      }
-    });
-
-    // Zod validated in SecureIpcLayer
-    this.ipc.setHandler('/workspace/exists', async (input: { name: string }) => {
-      try {
-        const workspace = await this.findWorkspaceByIdOrName(input.name);
-        return { exists: workspace !== undefined, id: workspace?.id };
-      } catch {
-        // Don't throw errors for existence checks - just return false
-        return { exists: false, id: undefined };
-      }
-    });
-
-    this.ipc.setHandler('/workspace/touch', async (input: { id: string }) => {
-      try {
-        const now = Math.floor(Date.now() / 1000);
-
-        // If the identifier is not a UUID, resolve it by name first
-        const isUuid =
-          /^[\da-f]{8}-[\da-f]{4}-[1-5][\da-f]{3}-[89ab][\da-f]{3}-[\da-f]{12}$/i.test(input.id);
-
-        let targetId = input.id;
-        if (!isUuid) {
-          const row = await this.db.database.get(
-            'SELECT id FROM workspaces WHERE LOWER(name) = LOWER(TRIM(?)) LIMIT 1',
-            [input.id]
-          ) as { id: string } | undefined;
-          if (row?.id) {
-            targetId = row.id;
-          }
-        }
-
-        const result = await this.db.database.run(
-          'UPDATE workspaces SET last_accessed = ? WHERE id = ?',
-          [now, targetId]
-        );
-        
-        if (result.changes === 0) {
-          throw new Error(`Workspace '${input.id}' not found during access time update. Workspace may have been deleted.`);
-        }
-
-        // Broadcast update to notify all renderer processes
-        this.broadcastUpdate('/workspace/current:update');
-
-        return true;
-      } catch (error) {
-        const errorMessage = (error as Error).message;
-        if (errorMessage.includes('not found')) {
-          throw error;
-        }
-        throw new Error(`Failed to update access time for workspace '${input.id}': ${errorMessage}. Check database permissions.`);
-      }
-    });
-
-    this.ipc.setHandler('/workspace/rename', async (input: { id: string; newName: string }) => {
-      try {
-        const result = await this.db.database.run(
-          'UPDATE workspaces SET name = ? WHERE id = ?',
-          [input.newName, input.id]
-        );
-        
-        if (result.changes === 0) {
-          throw new Error(`Workspace '${input.id}' not found during rename operation. Verify workspace exists before renaming.`);
-        }
-        
-        return true;
-      } catch (error) {
-        const err = error as { code?: string; message?: string };
-        const errorMessage = err.message || 'Unknown error';
-        if (errorMessage.includes('not found')) {
-          throw error;
-        }
-        if (err.code === 'SQLITE_CONSTRAINT_UNIQUE') {
-          throw new Error(`Cannot rename workspace to '${input.newName}': A workspace with this name already exists. Choose a different name.`);
-        }
-        throw new Error(`Failed to rename workspace '${input.id}' to '${input.newName}': ${errorMessage}. Check for name conflicts and database permissions.`);
-      }
-    });
-
-    // File content handlers
-    this.ipc.setHandler('/file/content', async (input: { workspaceId: string; filePath: string; lineRanges?: { start: number; end: number }[] }) => {
-      try {
-        // Check if content exists in database
-        const file = await this.db.database.get(
-          'SELECT content_hash, token_count FROM files WHERE workspace_id = ? AND path = ?',
-          [input.workspaceId, input.filePath]
-        ) as { content_hash: string; token_count: number } | undefined;
-        
-        if (file?.content_hash) {
-          try {
-            // Retrieve from content store
-            const content = await this.contentDeduplicator.retrieveContent(file.content_hash);
-            
-            // Apply line ranges if specified
-            if (input.lineRanges) {
-              const lines = content.split('
');
-              const selectedLines = input.lineRanges.flatMap(range => 
-                lines.slice(range.start - 1, range.end)
-              );
-              
-              return {
-                content: selectedLines.join('
'),
-                tokenCount: this.estimateTokenCount(selectedLines.join('
')),
-                hash: file.content_hash,
-                compressed: true
-              };
-            }
-            
-            return {
-              content,
-              tokenCount: file.token_count,
-              hash: file.content_hash,
-              compressed: true
-            };
-          } catch (contentError) {
-            throw new Error(`Failed to retrieve cached content for file '${input.filePath}' in workspace '${input.workspaceId}': ${(contentError as Error).message}. Falling back to filesystem.`);
-          }
-        }
-      } catch (dbError) {
-        console.warn(`Database lookup failed for file '${input.filePath}' in workspace '${input.workspaceId}': ${(dbError as Error).message}. Loading from filesystem.`);
-      }
-      
-      try {
-        // Load from file system
-        const content = await fs.readFile(input.filePath, 'utf8');
-        const tokenCount = countTokens(content);
-        
-        // Store for future use
-        const hash = await this.contentDeduplicator.storeFileContent(
-          content,
-          input.filePath
-        );
-        
-        await this.db.database.run(
-          'INSERT OR REPLACE INTO files (path, workspace_id, content_hash, size, is_binary, token_count) VALUES (?, ?, ?, ?, ?, ?)',
-          [input.filePath, input.workspaceId, hash, content.length, false, tokenCount]
-        );
-        
-        return {
-          content,
-          tokenCount,
-          hash,
-          compressed: false
-        };
-      } catch (error) {
-        throw new Error(`Failed to load file content from '${input.filePath}' for workspace '${input.workspaceId}': ${(error as Error).message}. Verify file exists and is readable.`);
-      }
-    });
-
-    // Prompt handlers
-    this.ipc.setHandler('/prompts/system', async () => {
-      try {
-        const prompts = await this.db.database.all(
-          'SELECT * FROM prompts WHERE type = ? AND is_active = 1',
-          ['system']
-        ) as {
-          id: string;
-          type: string;
-          name: string;
-          content: string;
-          token_count: number;
-          is_active: number;
-          created_at: number;
-          updated_at: number;
-        }[];
-        
-        return prompts.map(p => ({
-          id: p.id,
-          type: p.type,
-          name: p.name,
-          content: p.content,
-          tokenCount: p.token_count,
-          isActive: p.is_active === 1,
-          createdAt: p.created_at,
-          updatedAt: p.updated_at
-        }));
-      } catch (error) {
-        throw new Error(`Failed to load system prompts: ${(error as Error).message}. Check database connection and prompts table integrity.`);
-      }
-    });
-
-    this.ipc.setHandler('/prompts/role', async () => {
-      try {
-        const prompts = await this.db.database.all(
-          'SELECT * FROM prompts WHERE type = ? AND is_active = 1',
-          ['role']
-        ) as {
-          id: string;
-          type: string;
-          name: string;
-          content: string;
-          token_count: number;
-          is_active: number;
-          created_at: number;
-          updated_at: number;
-        }[];
-        
-        return prompts.map(p => ({
-          id: p.id,
-          type: p.type,
-          name: p.name,
-          content: p.content,
-          tokenCount: p.token_count,
-          isActive: p.is_active === 1,
-          createdAt: p.created_at,
-          updatedAt: p.updated_at
-        }));
-      } catch (error) {
-        throw new Error(`Failed to load role prompts: ${(error as Error).message}. Check database connection and prompts table integrity.`);
-      }
-    });
-
-    this.ipc.setHandler('/prompts/system/add', async (input: { id: string; name: string; content: string; isActive?: boolean }) => {
-      try {
-        const now = Math.floor(Date.now() / 1000);
-        const tokenCount = countTokens(input.content);
-        
-        await this.db.database.run(
-          'INSERT INTO prompts (id, type, name, content, token_count, is_active, created_at, updated_at) VALUES (?, ?, ?, ?, ?, ?, ?, ?)',
-          [input.id, 'system', input.name, input.content, tokenCount, input.isActive ? 1 : 0, now, now]
-        );
-        
-        // Notify all windows
-        this.broadcastUpdate('/prompts/system:update');
-        
-        return true;
-      } catch (error) {
-        const err = error as { code?: string; message?: string };
-        if (err.code === 'SQLITE_CONSTRAINT_UNIQUE') {
-          throw new Error(`Cannot add system prompt '${input.name}': A prompt with this ID already exists. Use update operation instead.`);
-        }
-        throw new Error(`Failed to add system prompt '${input.name}': ${err.message || 'Unknown error'}. Check prompt data format and database permissions.`);
-      }
-    });
-
-    this.ipc.setHandler('/prompts/system/update', async (input: { id: string; updates: { name?: string; content?: string; isActive?: boolean } }) => {
-      try {
-        const now = Math.floor(Date.now() / 1000);
-        const updates = input.updates;
-        
-        // Build dynamic update query
-        const fields: string[] = [];
-        const values: unknown[] = [];
-        
-        if ('name' in updates) {
-          fields.push('name = ?');
-          values.push(updates.name);
-        }
-        if ('content' in updates) {
-          fields.push('content = ?', 'token_count = ?');
-          values.push(updates.content, countTokens(updates.content as string));
-        }
-        if ('isActive' in updates) {
-          fields.push('is_active = ?');
-          values.push(updates.isActive ? 1 : 0);
-        }
-        
-        fields.push('updated_at = ?');
-        values.push(now, input.id);
-        
-        const result = await this.db.database.run(
-          `UPDATE prompts SET ${fields.join(', ')} WHERE id = ?`,
-          values
-        );
-        
-        if (result.changes === 0) {
-          throw new Error(`System prompt '${input.id}' not found during update operation. Verify prompt exists before updating.`);
-        }
-        
-        this.broadcastUpdate('/prompts/system:update');
-        return true;
-      } catch (error) {
-        const errorMessage = (error as Error).message;
-        if (errorMessage.includes('not found')) {
-          throw error;
-        }
-        throw new Error(`Failed to update system prompt '${input.id}': ${errorMessage}. Check prompt data format and database permissions.`);
-      }
-    });
-
-    this.ipc.setHandler('/prompts/system/delete', async (input: { id: string }) => {
-      try {
-        const result = await this.db.database.run('DELETE FROM prompts WHERE id = ?', [input.id]);
-        
-        if (result.changes === 0) {
-          throw new Error(`System prompt '${input.id}' not found during delete operation. Prompt may have already been deleted.`);
-        }
-        
-        this.broadcastUpdate('/prompts/system:update');
-        return true;
-      } catch (error) {
-        const errorMessage = (error as Error).message;
-        if (errorMessage.includes('not found')) {
-          throw error;
-        }
-        throw new Error(`Failed to delete system prompt '${input.id}': ${errorMessage}. Check database permissions and prompt references.`);
-      }
-    });
-
-    // Role prompt handlers (similar pattern)
-    this.ipc.setHandler('/prompts/role/add', async (input: { id: string; name: string; content: string; isActive?: boolean }) => {
-      try {
-        const now = Math.floor(Date.now() / 1000);
-        const tokenCount = countTokens(input.content);
-        
-        await this.db.database.run(
-          'INSERT INTO prompts (id, type, name, content, token_count, is_active, created_at, updated_at) VALUES (?, ?, ?, ?, ?, ?, ?, ?)',
-          [input.id, 'role', input.name, input.content, tokenCount, input.isActive ? 1 : 0, now, now]
-        );
-        
-        this.broadcastUpdate('/prompts/role:update');
-        return true;
-      } catch (error) {
-        const err = error as { code?: string; message?: string };
-        if (err.code === 'SQLITE_CONSTRAINT_UNIQUE') {
-          throw new Error(`Cannot add role prompt '${input.name}': A prompt with this ID already exists. Use update operation instead.`);
-        }
-        throw new Error(`Failed to add role prompt '${input.name}': ${err.message || 'Unknown error'}. Check prompt data format and database permissions.`);
-      }
-    });
-
-    this.ipc.setHandler('/prompts/role/update', async (input: { id: string; updates: { name?: string; content?: string; isActive?: boolean } }) => {
-      try {
-        const now = Math.floor(Date.now() / 1000);
-        const updates = input.updates;
-        
-        const fields: string[] = [];
-        const values: unknown[] = [];
-        
-        if ('name' in updates) {
-          fields.push('name = ?');
-          values.push(updates.name);
-        }
-        if ('content' in updates) {
-          fields.push('content = ?', 'token_count = ?');
-          values.push(updates.content, countTokens(updates.content as string));
-        }
-        if ('isActive' in updates) {
-          fields.push('is_active = ?');
-          values.push(updates.isActive ? 1 : 0);
-        }
-        
-        fields.push('updated_at = ?');
-        values.push(now, input.id);
-        
-        const result = await this.db.database.run(
-          `UPDATE prompts SET ${fields.join(', ')} WHERE id = ?`,
-          values
-        );
-        
-        if (result.changes === 0) {
-          throw new Error(`Role prompt '${input.id}' not found during update operation. Verify prompt exists before updating.`);
-        }
-        
-        this.broadcastUpdate('/prompts/role:update');
-        return true;
-      } catch (error) {
-        const errorMessage = (error as Error).message;
-        if (errorMessage.includes('not found')) {
-          throw error;
-        }
-        throw new Error(`Failed to update role prompt '${input.id}': ${errorMessage}. Check prompt data format and database permissions.`);
-      }
-    });
-
-    this.ipc.setHandler('/prompts/role/delete', async (input: { id: string }) => {
-      try {
-        const result = await this.db.database.run('DELETE FROM prompts WHERE id = ?', [input.id]);
-        
-        if (result.changes === 0) {
-          throw new Error(`Role prompt '${input.id}' not found during delete operation. Prompt may have already been deleted.`);
-        }
-        
-        this.broadcastUpdate('/prompts/role:update');
-        return true;
-      } catch (error) {
-        const errorMessage = (error as Error).message;
-        if (errorMessage.includes('not found')) {
-          throw error;
-        }
-        throw new Error(`Failed to delete role prompt '${input.id}': ${errorMessage}. Check database permissions and prompt references.`);
-      }
-    });
-
-    // Active prompts handlers
-    this.ipc.setHandler('/prompts/active', async () => {
-      try {
-        // Get active prompt selections from preferences
-        const systemPromptIds = await this.db.getPreference('active_system_prompts') || [];
-        const rolePromptIds = await this.db.getPreference('active_role_prompts') || [];
-        
-        return {
-          systemPromptIds,
-          rolePromptIds
-        };
-      } catch (error) {
-        throw new Error(`Failed to get active prompts: ${(error as Error).message}. Check database connection and preferences table.`);
-      }
-    });
-
-    this.ipc.setHandler('/prompts/active/update', async (input: { systemPromptIds?: string[]; rolePromptIds?: string[] }) => {
-      try {
-        await this.db.setPreference('active_system_prompts', input.systemPromptIds);
-        await this.db.setPreference('active_role_prompts', input.rolePromptIds);
-        
-        this.broadcastUpdate('/prompts/active:update');
-        return true;
-      } catch (error) {
-        throw new Error(`Failed to update active prompts (system: ${input.systemPromptIds?.length || 0}, role: ${input.rolePromptIds?.length || 0}): ${(error as Error).message}. Check prompt IDs and database permissions.`);
-      }
-    });
-
-    this.ipc.setHandler('/prompts/active/clear', async () => {
-      try {
-        await this.db.setPreference('active_system_prompts', []);
-        await this.db.setPreference('active_role_prompts', []);
-        
-        this.broadcastUpdate('/prompts/active:update');
-        return true;
-      } catch (error) {
-        throw new Error(`Failed to clear active prompts: ${(error as Error).message}. Check database permissions.`);
-      }
-    });
-
-    // Instructions handlers
-    this.ipc.setHandler('/instructions/list', async () => {
-      try {
-        const items = await this.db.database.listInstructions();
-        // Map DB snake_case fields to API camelCase schema
-        return items.map((row: any) => ({
-          id: row.id,
-          name: row.name,
-          content: row.content,
-          createdAt: row.created_at,
-          updatedAt: row.updated_at
-        }));
-      } catch (error) {
-        throw new Error(`Failed to list instructions: ${(error as Error).message}`);
-      }
-    });
-
-    this.ipc.setHandler('/instructions/create', async (input: { id: string; name: string; content: string }) => {
-      try {
-        await this.db.database.createInstruction(input.id, input.name, input.content);
-
-        // Broadcast update to notify all renderer processes
-        this.broadcastUpdate('/instructions/list:update');
-
-        return { success: true };
-      } catch (error) {
-        throw new Error(`Failed to create instruction: ${(error as Error).message}`);
-      }
-    });
-
-    this.ipc.setHandler('/instructions/update', async (input: { id: string; name: string; content: string }) => {
-      try {
-        await this.db.database.updateInstruction(input.id, input.name, input.content);
-
-        // Broadcast update to notify all renderer processes
-        this.broadcastUpdate('/instructions/list:update');
-
-        return { success: true };
-      } catch (error) {
-        throw new Error(`Failed to update instruction: ${(error as Error).message}`);
-      }
-    });
-
-    this.ipc.setHandler('/instructions/delete', async (input: { id: string }) => {
-      try {
-        await this.db.database.deleteInstruction(input.id);
-        return { success: true };
-      } catch (error) {
-        throw new Error(`Failed to delete instruction: ${(error as Error).message}`);
-      }
-    });
-
-    // Preference handlers
-    this.ipc.setHandler('/prefs/get', async (input: { key: string }) => {
-      try {
-        const pref = await this.db.database.get(
-          'SELECT value, encrypted FROM preferences WHERE key = ?',
-          [input.key]
-        ) as { value: string; encrypted: number } | undefined;
-        
-        if (!pref) {
-          return null;
-        }
-        
-        let value = pref.value;
-        
-        if (pref.encrypted) {
-          // Decrypt value using secure database method
-          value = await this.db.decryptValue(value);
-        }
-        
-        return JSON.parse(value);
-      } catch (error) {
-        throw new Error(`Failed to get preference '${input.key}': ${(error as Error).message}. Check key format and database connection.`);
-      }
-    });
-
-    this.ipc.setHandler('/prefs/set', async (input: { key: string; value: unknown; encrypted?: boolean }) => {
-      try {
-        let value = JSON.stringify(input.value);
-
-        if (input.encrypted) {
-          // Encrypt sensitive values
-          value = await this.db.encryptValue(value);
-        }
-
-        const now = Math.floor(Date.now() / 1000);
-
-        await this.db.database.run(
-          'INSERT OR REPLACE INTO preferences (key, value, encrypted, updated_at) VALUES (?, ?, ?, ?)',
-          [input.key, value, input.encrypted ? 1 : 0, now]
-        );
-
-        // Broadcast update to notify all renderer processes
-        this.broadcastUpdate('/prefs/get:update');
-
-        return true;
-      } catch (error) {
-        throw new Error(`Failed to set preference '${input.key}': ${(error as Error).message}. Check value format and database permissions.`);
-      }
-    });
-
-    // Selection state handlers
-    this.ipc.setHandler('/workspace/selection', async () => {
-      try {
-        return await this.db.getPreference('workspace_selection') || {
-          selectedFiles: [],
-          lastModified: Date.now()
-        };
-      } catch (error) {
-        throw new Error(`Failed to get workspace selection: ${(error as Error).message}. Check database connection and preferences.`);
-      }
-    });
-
-    this.ipc.setHandler('/workspace/selection/update', async (input: { selectedFiles?: unknown[]; lastModified?: number }) => {
-      try {
-        await this.db.setPreference('workspace_selection', input);
-        
-        this.broadcastUpdate('/workspace/selection:update', input);
-        return true;
-      } catch (error) {
-        const fileCount = input?.selectedFiles?.length || 0;
-        throw new Error(`Failed to update workspace selection (${fileCount} files): ${(error as Error).message}. Check selection data format and database permissions.`);
-      }
-    });
-
-    this.ipc.setHandler('/workspace/selection/clear', async () => {
-      try {
-        const cleared = {
-          selectedFiles: [],
-          lastModified: Date.now()
-        };
-        
-        await this.db.setPreference('workspace_selection', cleared);
-        
-        this.broadcastUpdate('/workspace/selection:update', cleared);
-        return true;
-      } catch (error) {
-        throw new Error(`Failed to clear workspace selection: ${(error as Error).message}. Check database permissions.`);
-      }
-    });
-  }
-
-  private broadcastUpdate(channel: string, data?: unknown) {
-    const windows = BrowserWindow.getAllWindows();
-    for (const window of windows) {
-      window.webContents.send(channel, data);
-    }
-  }
-}
\ No newline at end of file
diff --git a/src/main/ipc/index.ts b/src/main/ipc/index.ts
index 7f9ec1b..10d7437 100644
--- a/src/main/ipc/index.ts
+++ b/src/main/ipc/index.ts
@@ -1,2 +1,2 @@
-export { SecureIpcLayer } from './secure-ipc';
+// SecureIpcLayer has been removed
 export * from './schemas';
\ No newline at end of file
diff --git a/src/main/ipc/secure-ipc.ts b/src/main/ipc/secure-ipc.ts
deleted file mode 100644
index e18767c..0000000
--- a/src/main/ipc/secure-ipc.ts
+++ /dev/null
@@ -1,481 +0,0 @@
-import { ipcMain } from 'electron';
-import type Electron from 'electron';
-import { z, ZodSchema } from 'zod';
-import { RateLimiter } from 'limiter';
-
-import { RATE_LIMITS } from '../../constants/app-constants';
-
-// IPC channel configuration
-interface IpcChannelConfig<TInput, TOutput> {
-  input: ZodSchema<TInput>;
-  output: ZodSchema<TOutput>;
-  rateLimit: number;
-  handler?: (input: TInput, event: Electron.IpcMainInvokeEvent) => Promise<TOutput>;
-}
-
-// Channel category mapping for dynamic rate limiting
-type ChannelCategory = 'workspace' | 'file' | 'prompt' | 'prompts' | 'state' | 'prefs' | 'general';
-
-export class SecureIpcLayer {
-  private channels = new Map<string, IpcChannelConfig<unknown, unknown>>();
-  private rateLimiters = new Map<string, RateLimiter>();
-
-  constructor() {
-    this.setupChannels();
-  }
-
-  /**
-   * Determine rate limit based on channel category and operation type
-   */
-  private getRateLimit(channel: string): number {
-    // Parse channel path to determine category
-    const parts = channel.split('/').filter(Boolean);
-    const category = parts[0] as ChannelCategory;
-    const operation = parts[1];
-    
-    // Map categories to rate limit constants
-    switch (category) {
-      case 'workspace': {
-        // Workspace operations have different limits based on operation type
-        if (operation === 'list' || operation === 'current' || operation === 'selection') {
-          return RATE_LIMITS.REQUESTS.WORKSPACE_OPERATIONS;
-        }
-        if (operation === 'exists' || operation === 'touch') {
-          return RATE_LIMITS.REQUESTS.WORKSPACE_OPERATIONS * 2; // Higher for frequent checks
-        }
-        return RATE_LIMITS.REQUESTS.STATE_OPERATIONS;
-      }
-        
-      case 'file': {
-        // File operations have high limits due to frequent access
-        return operation === 'content' ? 
-          RATE_LIMITS.REQUESTS.FILE_CONTENT : 
-          RATE_LIMITS.REQUESTS.FILE_LIST;
-      }
-        
-      case 'prompt':
-      case 'prompts': {
-        // Prompt operations
-        return operation === 'list' || operation === 'active' ? 
-          RATE_LIMITS.REQUESTS.PROMPT_OPERATIONS :
-          RATE_LIMITS.REQUESTS.STATE_OPERATIONS;
-      }
-        
-      case 'prefs': {
-        // Preferences - read operations have higher limits
-        return operation === 'get' ? 
-          RATE_LIMITS.REQUESTS.FILE_LIST : // Use higher limit for frequent reads
-          RATE_LIMITS.REQUESTS.STATE_OPERATIONS;
-      }
-        
-      case 'state': {
-        // State operations
-        return RATE_LIMITS.REQUESTS.STATE_OPERATIONS;
-      }
-        
-      default: {
-        // Default to general limit
-        return RATE_LIMITS.REQUESTS.GENERAL;
-      }
-    }
-  }
-
-  private setupChannels() {
-    // Import schemas from generated CJS file
-    // eslint-disable-next-line @typescript-eslint/no-var-requires, unicorn/prefer-module
-    const schemas = require('../../../lib/main/ipc/schemas.cjs');
-    const {
-      WorkspaceSchema,
-      WorkspaceCreateSchema,
-      WorkspaceUpdateSchema,
-      WorkspaceDeleteSchema,
-      WorkspaceRenameSchema,
-      FileContentRequestSchema,
-      FileContentResponseSchema,
-      FileSaveSchema,
-      PreferenceGetSchema,
-      PreferenceSetSchema,
-      PromptSchema,
-      WorkspaceSelectionSchema,
-      WorkspaceSelectionUpdateSchema,
-      ActivePromptsSchema,
-      InstructionSchema,
-      InstructionCreateSchema
-    } = schemas;
-
-    // Define all IPC channels with their schemas
-    this.registerChannel('/workspace/list', {
-      input: z.object({}),
-      output: z.array(WorkspaceSchema),
-      rateLimit: this.getRateLimit('/workspace/list')
-    });
-
-    this.registerChannel('/workspace/create', {
-      input: WorkspaceCreateSchema,
-      output: WorkspaceSchema,
-      rateLimit: this.getRateLimit('/workspace/create')
-    });
-
-    this.registerChannel('/workspace/load', {
-      // Accept either a UUID or a workspace name as identifier
-      input: z.object({ id: z.string().min(1) }),
-      output: z.union([WorkspaceSchema, z.null()]),
-      rateLimit: this.getRateLimit('/workspace/load')
-    });
-
-    this.registerChannel('/workspace/exists', {
-      // Check if a workspace exists by name
-      input: z.object({ name: z.string().min(1) }),
-      output: z.object({ exists: z.boolean(), id: z.string().optional() }),
-      rateLimit: this.getRateLimit('/workspace/exists')
-    });
-
-    this.registerChannel('/workspace/update', {
-      input: WorkspaceUpdateSchema,
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/workspace/update')
-    });
-
-    this.registerChannel('/workspace/delete', {
-      input: WorkspaceDeleteSchema,
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/workspace/delete')
-    });
-
-    this.registerChannel('/file/content', {
-      input: FileContentRequestSchema,
-      output: FileContentResponseSchema,
-      rateLimit: this.getRateLimit('/file/content')
-    });
-
-    this.registerChannel('/file/save', {
-      input: FileSaveSchema,
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/file/save')
-    });
-
-    this.registerChannel('/prefs/get', {
-      input: PreferenceGetSchema,
-      output: z.unknown(),
-      rateLimit: this.getRateLimit('/prefs/get')
-    });
-
-    this.registerChannel('/prefs/set', {
-      input: PreferenceSetSchema,
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/prefs/set')
-    });
-
-    this.registerChannel('/prompt/list', {
-      input: z.object({ type: z.enum(['system', 'role']).optional() }),
-      output: z.array(PromptSchema),
-      rateLimit: this.getRateLimit('/prompt/list')
-    });
-
-    this.registerChannel('/prompt/create', {
-      input: PromptSchema.omit({ id: true, createdAt: true, updatedAt: true }),
-      output: PromptSchema,
-      rateLimit: this.getRateLimit('/prompt/create')
-    });
-
-    this.registerChannel('/prompt/update', {
-      input: PromptSchema,
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/prompt/update')
-    });
-
-    this.registerChannel('/prompt/delete', {
-      input: z.object({ id: z.string() }),
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/prompt/delete')
-    });
-
-    // State management channels
-    this.registerChannel('/workspace/current', {
-      input: z.object({}),
-      output: z.union([WorkspaceSchema, z.null()]),
-      rateLimit: this.getRateLimit('/workspace/current')
-    });
-
-    this.registerChannel('/workspace/set-current', {
-      input: z.object({ workspace: z.record(z.string(), z.unknown()) }),
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/workspace/set-current')
-    });
-
-    this.registerChannel('/workspace/clear', {
-      input: z.object({}),
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/workspace/clear')
-    });
-
-    this.registerChannel('/workspace/touch', {
-      // Accept either uuid or workspace name for backward compatibility
-      input: z.object({ id: z.string().min(1) }),
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/workspace/touch')
-    });
-
-    this.registerChannel('/workspace/rename', {
-      input: WorkspaceRenameSchema,
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/workspace/rename')
-    });
-
-    // Selection state channels
-    this.registerChannel('/workspace/selection', {
-      input: z.object({}),
-      output: WorkspaceSelectionSchema,
-      rateLimit: this.getRateLimit('/workspace/selection')
-    });
-
-    this.registerChannel('/workspace/selection/update', {
-      input: WorkspaceSelectionUpdateSchema,
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/workspace/selection/update')
-    });
-
-    this.registerChannel('/workspace/selection/clear', {
-      input: z.object({}),
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/workspace/selection/clear')
-    });
-
-    // Prompt state channels
-    this.registerChannel('/prompts/system', {
-      input: z.object({}),
-      output: z.array(PromptSchema),
-      rateLimit: this.getRateLimit('/prompts/system')
-    });
-
-    this.registerChannel('/prompts/role', {
-      input: z.object({}),
-      output: z.array(PromptSchema),
-      rateLimit: this.getRateLimit('/prompts/role')
-    });
-
-    this.registerChannel('/prompts/system/add', {
-      input: PromptSchema.omit({ createdAt: true, updatedAt: true }),
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/prompts/system/add')
-    });
-
-    this.registerChannel('/prompts/system/update', {
-      input: z.object({ id: z.string(), updates: z.record(z.string(), z.unknown()) }),
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/prompts/system/update')
-    });
-
-    this.registerChannel('/prompts/system/delete', {
-      input: z.object({ id: z.string() }),
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/prompts/system/delete')
-    });
-
-    this.registerChannel('/prompts/role/add', {
-      input: PromptSchema.omit({ createdAt: true, updatedAt: true }),
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/prompts/role/add')
-    });
-
-    this.registerChannel('/prompts/role/update', {
-      input: z.object({ id: z.string(), updates: z.record(z.string(), z.unknown()) }),
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/prompts/role/update')
-    });
-
-    this.registerChannel('/prompts/role/delete', {
-      input: z.object({ id: z.string() }),
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/prompts/role/delete')
-    });
-
-    this.registerChannel('/prompts/active', {
-      input: z.object({}),
-      output: ActivePromptsSchema,
-      rateLimit: this.getRateLimit('/prompts/active')
-    });
-
-    this.registerChannel('/prompts/active/update', {
-      input: ActivePromptsSchema,
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/prompts/active/update')
-    });
-
-    this.registerChannel('/prompts/active/clear', {
-      input: z.object({}),
-      output: z.boolean(),
-      rateLimit: this.getRateLimit('/prompts/active/clear')
-    });
-
-    // Instructions channels
-    this.registerChannel('/instructions/list', {
-      input: z.object({}),
-      output: z.array(InstructionSchema),
-      rateLimit: this.getRateLimit('/instructions/list')
-    });
-
-    this.registerChannel('/instructions/create', {
-      input: InstructionCreateSchema.extend({ id: z.string() }),
-      output: z.object({ success: z.boolean() }),
-      rateLimit: this.getRateLimit('/instructions/create')
-    });
-
-    this.registerChannel('/instructions/update', {
-      input: InstructionSchema.pick({ id: true, name: true, content: true }),
-      output: z.object({ success: z.boolean() }),
-      rateLimit: this.getRateLimit('/instructions/update')
-    });
-
-    this.registerChannel('/instructions/delete', {
-      input: z.object({ id: z.string() }),
-      output: z.object({ success: z.boolean() }),
-      rateLimit: this.getRateLimit('/instructions/delete')
-    });
-  }
-
-  registerChannel<TInput, TOutput>(
-    channel: string,
-    config: IpcChannelConfig<TInput, TOutput>
-  ) {
-    this.channels.set(channel, config as IpcChannelConfig<unknown, unknown>);
-    
-    // Create rate limiter
-    this.rateLimiters.set(channel, new RateLimiter({
-      tokensPerInterval: config.rateLimit,
-      interval: 'second',
-      fireImmediately: true
-    }));
-
-    // Register IPC handler
-    ipcMain.handle(channel, async (event: Electron.IpcMainInvokeEvent, rawInput: unknown) => {
-      try {
-        // Security checks
-        await this.performSecurityChecks(channel, event);
-        
-        // Rate limiting
-        await this.checkRateLimit(channel);
-        
-        // Input validation
-        const validatedInput = config.input.parse(rawInput);
-        
-        // Execute handler
-        let result: TOutput;
-        if (config.handler) {
-          result = await config.handler(validatedInput, event);
-        } else {
-          // Default handler (to be overridden)
-          throw new Error(`No handler registered for ${channel}`);
-        }
-        
-        // Output validation
-        return config.output.parse(result);
-        
-      } catch (error) {
-        console.error(`IPC error on ${channel}:`, error);
-        
-        if (error instanceof z.ZodError) {
-          throw new TypeError(`Validation error: ${error.message}`);
-        }
-        
-        throw error;
-      }
-    });
-  }
-
-  private async performSecurityChecks(
-    _channel: string,
-    event: Electron.IpcMainInvokeEvent
-  ) {
-    // Verify origin: allow file:// always; in dev allow localhost dev server
-    if (!event.senderFrame) {
-      throw new Error('Security check failed: No sender frame');
-    }
-    const url = event.senderFrame.url;
-
-    // Production/package: only allow file:// pages
-    if (url.startsWith('file://')) {
-      return;
-    }
-
-    // Development: permit Electron dev server origins (localhost/127.0.0.1)
-    const isDev = process.env.NODE_ENV !== 'production';
-    if (isDev) {
-      try {
-        const current = new URL(url);
-        const allowedOrigins = new Set<string>();
-
-        // Allow the origin from ELECTRON_START_URL if provided (e.g., http://localhost:5173)
-        const startUrl = process.env.ELECTRON_START_URL;
-        if (startUrl) {
-          try {
-            const su = new URL(startUrl);
-            allowedOrigins.add(`${su.protocol}//${su.host}`);
-          } catch {
-            // Invalid URL format in ELECTRON_START_URL - safe to ignore
-          }
-        }
-
-        // Common local dev origins
-        allowedOrigins.add('http://localhost:5173');
-        allowedOrigins.add('http://127.0.0.1:5173');
-
-        const origin = `${current.protocol}//${current.host}`;
-        if (
-          allowedOrigins.has(origin) ||
-          ((current.hostname === 'localhost' || current.hostname === '127.0.0.1') && (current.protocol === 'http:' || current.protocol === 'https:'))
-        ) {
-          return;
-        }
-      } catch {
-        // Fall through to error
-      }
-    }
-
-    throw new Error('Invalid origin');
-
-    // Additional checks can be added here
-    // - CSRF tokens
-    // - Session validation
-    // - Permission checks
-  }
-
-  private async checkRateLimit(channel: string) {
-    const limiter = this.rateLimiters.get(channel);
-    if (!limiter) {
-      throw new Error(`No rate limiter for channel: ${channel}`);
-    }
-
-    const hasToken = await limiter.tryRemoveTokens(1);
-    if (!hasToken) {
-      throw new Error('Rate limit exceeded');
-    }
-  }
-
-  // Set handler for a channel
-  setHandler<TInput, TOutput>(
-    channel: string,
-    handler: (input: TInput, event: Electron.IpcMainInvokeEvent) => Promise<TOutput>
-  ) {
-    const config = this.channels.get(channel);
-    if (!config) {
-      throw new Error(`Unknown channel: ${channel}`);
-    }
-    
-    config.handler = handler as (input: unknown, event: Electron.IpcMainInvokeEvent) => Promise<unknown>;
-  }
-
-  // Get registered channels (for testing/documentation)
-  getChannels(): string[] {
-    return [...this.channels.keys()];
-  }
-
-  // Unregister all handlers (for cleanup)
-  unregisterAll() {
-    for (const channel of this.channels.keys()) {
-      ipcMain.removeHandler(channel);
-    }
-    this.channels.clear();
-    this.rateLimiters.clear();
-  }
-}
\ No newline at end of file
diff --git a/tsconfig.main.json b/tsconfig.main.json
index 3f11591..b148498 100644
--- a/tsconfig.main.json
+++ b/tsconfig.main.json
@@ -18,24 +18,17 @@
     "types": []
   },
   "include": [
-    "src/constants/app-constants.ts",
-    "src/main/ipc/secure-ipc.ts",
     "src/main/ipc/schemas.ts",
-    "src/main/handlers/state-handlers.ts",
-    "src/main/db/database-manager.ts",
-    "src/main/db/secure-database.ts",
     "src/main/db/async-database.ts",
+    "src/main/db/connection-pool.ts", 
+    "src/main/db/pool-config.ts",
+    "src/main/db/pooled-database.ts",
+    "src/main/db/pooled-database-bridge.ts",
     "src/main/db/retry-utils.ts",
-    "src/main/db/shared-buffer-utils.ts",
-    "src/main/utils/token-utils.ts"
+    "src/main/db/shared-buffer-utils.ts"
   ],
   "exclude": [
-    "src/main/db/__tests__/**",
-    "src/main/db/index.ts",
-    "src/main/db/connection-pool.ts",
-    "src/main/db/pooled-*.ts",
-    "src/main/db/pool-config.ts",
-    "src/main/db/pooled-database-bridge.ts"
+    "src/main/db/__tests__/**"
   ]
 }
 
```
